---
title: "Trabajo Practico 2"
author: "Iair Embon & Alejandro Ramos Usaj"
date: '2022-06-18'
output: html_document
---

# 1 

```{r}
set.seed(1234)

# cargo los datos
root <- rprojroot::is_rstudio_project
basename(getwd())

data <- read.csv(root$find_file("GLM/encuesta.csv"))

# divido en entrenamiento y testeo 
library(dplyr)


#Correr esta linea por si se quieren retirar todos los valores que tienen 0 para las columnas que corresponden a una pregunta
# data <- data %>% filter(if_any(starts_with('Q'), ~ . > 0)) 

entrenamiento <- data %>%
  slice_sample(prop = 0.8)

testeo <- data %>%
  slice(-pull(entrenamiento,X))

```

# 2 

>Llamamos Q a la pregunta Q28

# 3

>El problema teorico de usar una regresion lineal es que la veriable de respuestas Y no es escalar, es decir, las distancias entre cada unidad no son equivaletes y la respuesta Y no es continua. 
Segun Agresti (2015), el modelo de regresion lineal podria utilizarse para ver que variables afectan Y pero presentaria algunas limitaciones. 
En primer lugar, si la respuesta es verbal en lugar de numerica, asignar valores numericos a categorias como 'Totalmente en desacuerdo' o 'Totalmente de acuerdo' seria muy arbitrario porque se podria decir que uno de los extremos representa el 1 y el otro el 5, o uno de los extremos representa el 1 y el otro el 10, o el 7 o cualquier otro numero. 
En segundo lugar, si asumimos que las respuestas ordinales responden a una variable continua latente, distintos valores de la variable latente podrian corresponderse con un mismo valor de la variable de respuesta ordinal. Esto se debe a que cualquier valor dentro del rango de dos umbrales va a corresponderse con el mismo valor ordinal aunque tengan distinto valor de la variable latente.
En tercer lugar el modelo lineal comun no otorga probabilidades estimadas a cada categoria ordinal, por lo que no seria claro como ordinalizar una prediccion numerica continua. 
Por ultimo, la variabilidad de los datos no es constante para la variable de respuesta. Es decir, la variabilidad de los valores latentes en un determinado rango ordinal es mayor a la que se obtiene en la variable de respuesta ordinal. Esto esta relacionado con el hecho de que los umbrales para los extremos no estan acotados en la distribucion de la variable latente.

>El porblema teorico al momento de usar una regresion multinomial para estos datos seria que no aprovecharia la caracteristica ordinal de la variable de respuesta. Un modelo ordinal tiene una ordenada dada por la categoria ordinal pero los coeficientes son los mismos independientemente de la categoria ya que se asume que el efecto de las covariadas es el mismo para cada probabilidad acumulada. De esta manera un modelo ordinal utilizaria muchos menos parametros, ya que los coeficientes no dependen de cada categoria como sucede en el modelo multinomial porque no se puede utilizar una estructura de probabilidad acumulada como la que se trabaja en un modelo ordinal. 

# 4

>Este modelo supone que las respuestas Y corresponden a una variable del tipo ordinal con J categorias. A diferencia del modelo multinomial clasico donde se quiere calcular, en ultima instancia, la probabilidad de pertenecer a cada categoria. En este caso aprovechamos la estructura ordinal asumiendo que existe una variable latente que desconocemos a partir de la cual con determinados umbrales numericos se construyeron las respuestas ordinales observadas. La probabilidad de que la respuesta y sea igual a la categoria ordinal j puede pensarse como una probabilidad acumulada. Lo que se intenta modelar entonces es la probabilidad acumulada de que la respuesta sea menor o igual a j, dado determinado efecto de las covariadas y determinados puntos de corte, ambos parametros a estimar. Se puede repensar entonces la probabilidad de que la respuesta sea menor o igual a la categoria j como la probabilidad de que el valor de la variable latente sea menor o igual al punto de corte de la categoria j es decir la funcion de probabilidad acumulada. Si asuminos que la funcion de probabilidad acumulada es la logistica standard, entonces la funcion de link (que es la inversa de probabilidad acumulada) es el logit. Por otro lado, si asumimos que es la acumulada de la normal, entonces utilizamos como link la funcion probit. En este modelo, la intercept es diferente para cada J, mientras que el slope es el mismo.

# 5

```{r}
library(MASS)
library(tidyverse)

# exloro la variable age
hist(entrenamiento$age)

# hay una edad que tiene 353 a√±os, y uno de 99. quizas es mejor sacar esos dos
entrenamiento <- entrenamiento %>% filter(age < 99)
testeo <- testeo %>% filter(age < 99)

# exploro Q28
hist(entrenamiento$Q28)
table(entrenamiento$Q28)

# es raro porque hay 24 casos con respuesta 0,
entrenamiento <- entrenamiento %>% filter(Q28 != 0) 
testeo <- testeo %>% filter(Q28 != 0)
#Filtramos los datos con valor de respuesta 0

# exploro Q28 en funcion de la edad.
plot(entrenamiento$age, entrenamiento$Q28, xlim = c(10,100))

# corro el modelo
modelo_q28 <- polr(as.factor(Q28) ~ age, data = entrenamiento)
summary(modelo_q28)

# predigo Q28 en funcion de la edad
predicciones_q28 <- predict(modelo_q28, testeo)
```

# 6

```{r}
# primero corremos el modelo
modelo_q9 <- polr( as.factor(Q9) ~ age, data = entrenamiento)
summary(modelo_q9)

#armo el dataframe de input
df_25 <- data.frame(age = c(25))
# hago una prediccion con el modelo
predicciones_q9 <- predict(modelo_q9, df_25, type = "p")

#Resultado del ejercicio, sumo la probabilidad para todas las opciones menores o iguales a 4
sum(predicciones_q9[0:5])
```

# 7

Defino la funcion de perdida

```{r}
funcion_perdida <- function(predicciones, variable_respuesta){
  diferencia_absoluta <- abs(predicciones - variable_respuesta)
  perdida <- sum(diferencia_absoluta)/length(variable_respuesta)
  return(perdida)
}
```

Evaluamos la funcion con los dos modelos creados hasta ahora.

```{r}
# Primero hago las predicciones ##### CORREGIR, O RESOLVER
predicciones_q9 <- predict(modelo_q9, df_25, type = "p")

funcion_perdida(as.numeric(predicciones_q28), testeo$Q28)
funcion_perdida(predicciones_q9, testeo$Q9)
```

# 8

Primero armo y ajusto el modelo lineal

```{r}
# corro el modelo lineal
modelo_lineal_q28 <- lm(Q28 ~ age, data = entrenamiento)
summary(modelo_lineal_q28)
```

En segundo lugar, genero una funcion que tome las predicciones del modelo y las acote a los valores ordinales que puede tomar la variable de respuesta.

```{r}
pred_linear_fun <- function(predicciones){
  predicciones_redondeadas <- round(predicciones)
  #Redondeo a 1 si da menor que 1 y a 5 si da mayor que 5
  predicciones_ajustadas <- sapply(
    predicciones_redondeadas,
     function(x) ifelse(x < 1, 1, 
                        ifelse(x > 5, 5, x))
     )
  return(predicciones_ajustadas)
}
```

Implemento la funcion con las predicciones del modelo lineal

```{r}
predicciones_linear_q28 <- pred_linear_fun(predict(modelo_lineal_q28, testeo))
```

# 9

```{r}
# veo los resultados de las funciones de perdidas anterior
perdida_lineal_q28 <- funcion_perdida(
  predicciones_linear_q28,
  testeo$Q28
)
perdida_ordinal_q28 <- funcion_perdida(
  as.numeric(predicciones_q28),
  testeo$Q28
)

c(
  'Perdida Lineal' = perdida_lineal_q28,
  'Perdida Ordinal' = perdida_ordinal_q28
)
```

Parece ser que el modelo lineal presenta una menor funcion de perdida que el modelo de regresion ordinal.

# 10 #### lo rompi, CORREGIR

El modelo de regresion ordinal puede utilizar diferentes funciones de link por lo que vamos implementar una funcion que pruebe todas las posbiles funciones de link para cada combinacion de covariadas. 

```{r}
library(purrr)
# corro varios modelos cada uno con su link function
link_functions <- c("logistic", "probit", "loglog", "cauchit")

varios_modelos <- link_functions %>%
  map(~ polr(formula, data = entrenamiento, method = .x)) %>%
  map(~ funcion_de_perdida(predict(.x, testeo), testeo$Q28))

# realizo predicciones en el df de testeo y uso la funcion de perdida del ejercicio 7
funcion_de_perdida <- rep(NaN, length(varios_modelos))
  
for (i in 1:length(varios_modelos)){
  predicciones <- predict(varios_modelos[[i]], testeo)
  funcion_de_perdida[i] <- sum(abs(as.numeric(testeo$Q28) - as.numeric(predicciones)))/nrow(testeo)}
  
index_min <- which.min(funcion_de_perdida)
  
# la link function que tiene menor error segun la funcion de perdida implementada es:
link_functions[index_min]

```

# 11

Exploro algunas variables que nos parecen interesantes como posibles predictores de titulo universitario

```{r}
# genero
table(data$gender)
# es raro que aparezca el 0, ya que no esta en el codebook.txt,
# lo voy a sacar
entrenamiento <- entrenamiento %>% filter(gender != 0)
testeo <- testeo %>% filter(gender != 0)

# Q11	I did not work very hard in school.
hist(data$Q11)
table(data$Q11)
# saco a los datos con respuesta 0
entrenamiento <- entrenamiento %>% filter(Q11 != 0)
testeo <- testeo %>% filter(Q11 != 0)

# Q30	I think horoscopes are fun.
hist(data$Q30)
table(data$Q30)
# saco a los datos con respuesta 0
entrenamiento <- entrenamiento %>% filter(Q30 != 0)
testeo <- testeo %>% filter(Q30 != 0)

# Q32	I have thought about becoming a vegetarian.
hist(data$Q32)
table(data$Q32)
# saco a los datos con respuesta 0
entrenamiento <- entrenamiento %>% filter(Q32 != 0)
testeo <- testeo %>% filter(Q32 != 0)

```

Preparo el df para correr el modelo. 
En la pregunta "How much education have you completed?":
No tiene titulo universitario = 1=Less than high school, 2=High school
Tiene titulo universitario = 3=University degree, 4=Graduate degree

```{r}
# exploro la variable de educacion
hist(data$education)
table(data$education)
# saco a los datos con respuesta 0
entrenamiento <- entrenamiento %>% filter(education != 0)
testeo <- testeo %>% filter(education != 0)

entrenamiento$education_universitaria<- ifelse(entrenamiento$education == 1 | entrenamiento$education == 2, 0, 1)

testeo$education_universitaria<- ifelse(testeo$education == 1 | testeo$education == 2, 0, 1)
```


Corro el modelo

```{r}
mod_log <- glm(education_universitaria ~ gender +
           Q11 +
           Q30 +
           Q32,
           family=binomial(link="logit"), 
           data = entrenamiento)

summary(mod_log)
```

Calculo el error segun la exactitud

```{r}
# voy a probar correr un modelo mas simple
mod_log <- glm(education_universitaria ~ 
                  gender +
                  Q11 +
                  Q30+
                  Q32+
                  age,
           family=binomial(link="logit"), 
           data = entrenamiento)

summary(mod_log)

predicciones_mod_log <- predict(mod_log, testeo, type="response")
hist(predicciones_mod_log2)

predicted.classes <- ifelse(predicciones_mod_log > 0.5, 1, 0)

# veo exactitud
mean(predicted.classes == testeo$education_universitaria)

```

# 12

En primer lugar generamos varias muestras aleatorias de nuestro dataframe, con distinto n pero sin repeticion. Para eso armamos una distribucion uniforme entre los dos rangos de valores que consideramos apropiados. Vamos a usar 1000 muestras a partir de un rango de entre 50 y 5000 datos. 

Armamos para esto una funcion la cual, en cada iteracion saca una muestra de la distribucion uniforme que definimos y seleciona una muestra aleatoria de nuestros datos con ese muestral. 

```{r}
random_sampling_fun <- function(){
  random_n <- runif(50,5000)
  datos_sampleados <- entrenamiento %>% dplyr::slice_sample(random_n)
  return(datos_sampleados)
}
```

Generamos otra funcion que va a utilizar los datos creados por la funcion `random_sampling_fun` y los va a usar para ajustar un modelo de regresion logistica calculando la exactitud. La exactitud siempre se calcula sobre el conjunto de testeo que tiene un tama√±o fijo. De esta manera la funcion otorga un vector de dos valores, uno indicando la cantidad de datos utilizados y otro indicando el valor de exactitud obtenido.

```{r}
random_fit_predict <- function(){
  datos_muestrales <- random_sampling_fun
  n_muestral <- nrow(datos_muestrales)
  #Aca va el modelo de regresion logistica
  #modelo <- 
  
  #Aca va la funcion de calculo de exactitud
  #exactitud <- 
  resultado <- c('N' = n_muestral, 'Exactitud' = exactitud)
  return(resultado)
}
```

Una vez definidas ambas funciones las integramos en un loop que corra 1000 veces para obtener 1000 pares de combinaciones de tama√±o muestral y exactitud.

```{r}
multiple_log <- replicate(1000, random_fit_predict)
```
