---
title: "Trabajo Practico 2"
author: "Iair Embon & Alejandro Ramos Usaj"
date: '2022-06-18'
output: html_document
---

# 1 

```{r}
set.seed(1234)

# cargo los datos
root <- rprojroot::is_rstudio_project
basename(getwd())

data <- read.csv(root$find_file("GLM/encuesta.csv"))

# divido en entrenamiento y testeo 
library(dplyr)

entrenamiento <- data %>%
  slice_sample(prop = 0.8)

testeo <- data %>%
  slice(-pull(entrenamiento,X))

```

# 2 

>Llamamos Q a la pregunta Q28

# 3

>El problema teorico de usar una regresion lineal es que la veriable de respuestas Y no es escalar, es decir, las distancias entre cada unidad no son equivaletes y la respuesta Y no es continua. 
Segun Agresti (2015), el modelo de regresion lineal podria utilizarse para ver que variables afectan Y pero presentaria algunas limitaciones. 
En primer lugar, si la respuesta es verbal en lugar de numerica, asignar valores numericos a categorias como 'Totalmente en desacuerdo' o 'Totalmente de acuerdo' seria muy arbitrario porque se podria decir que uno de los extremos representa el 1 y el otro el 5, o uno de los extremos representa el 1 y el otro el 10, o el 7 o cualquier otro numero. 
En segundo lugar, si asumimos que las respuestas ordinales responden a una variable continua latente, distintos valores de la variable latente podrian corresponderse con un mismo valor de la variable de respuesta ordinal. Esto se debe a que cualquier valor dentro del rango de dos umbrales va a corresponderse con el mismo valor ordinal aunque tengan distinto valor de la variable latente.
En tercer lugar el modelo lineal comun no otorga probabilidades estimadas a cada categoria ordinal, por lo que no seria claro como ordinalizar una prediccion numerica continua. 
Por ultimo, la variabilidad de los datos no es constante para la variable de respuesta. Es decir, la variabilidad de los valores latentes en un determinado rango ordinal es mayor a la que se obtiene en la variable de respuesta ordinal. Esto esta relacionado con el hecho de que los umbrales para los extremos no estan acotados en la distribucion de la variable latente.

>El porblema teorico al momento de usar una regresion multinomial para estos datos seria que no aprovecharia la caracteristica ordinal de la variable de respuesta. Un modelo ordinal tiene una ordenada dada por la categoria ordinal pero los coeficientes son los mismos independientemente de la categoria ya que se asume que el efecto de las covariadas es el mismo para cada probabilidad acumulada. De esta manera un modelo ordinal utilizaria muchos menos parametros, ya que los coeficientes no dependen de cada categoria como sucede en el modelo multinomial porque no se puede utilizar una estructura de probabilidad acumulada como la que se trabaja en un modelo ordinal. 

# 4

>Este modelo supone que las respuestas Y corresponden a una variable del tipo ordinal con J categorias. A diferencia del modelo multinomial clasico donde se quiere calcular, en ultima instancia, la probabilidad de pertenecer a cada categoria. En este caso aprovechamos la estructura ordinal asumiendo que existe una variable latente que desconocemos a partir de la cual con determinados umbrales numericos se construyeron las respuestas ordinales observadas. La probabilidad de que la respuesta y sea igual a la categoria ordinal j puede pensarse como una probabilidad acumulada. Lo que se intenta modelar entonces es la probabilidad acumulada de que la respuesta sea menor o igual a j, dado determinado efecto de las covariadas y determinados puntos de corte, ambos parametros a estimar. Se puede repensar entonces la probabilidad de que la respuesta sea menor o igual a la categoria j como la probabilidad de que el valor de la variable latente sea menor o igual al punto de corte de la categoria j es decir la funcion de probabilidad acumulada. Si asuminos que la funcion de probabilidad acumulada es la logistica standard, entonces la funcion de link (que es la inversa de probabilidad acumulada) es el logit. Por otro lado, si asumimos que es la acumulada de la normal, entonces utilizamos como link la funcion probit. En este modelo, la intercept es diferente para cada J, mientras que el slope es el mismo.

# 5

```{r}
library(MASS)
library(tidyverse)

# exloro la variable age
hist(entrenamiento$age)

# hay una edad que tiene 353 a√±os, y uno de 99. quizas es mejor sacar esos dos
entrenamiento <- entrenamiento %>% filter(age < 99)
testeo <- testeo %>% filter(age < 99)

# exploro Q28
hist(entrenamiento$Q28)
table(entrenamiento$Q28)

# es raro porque hay 24 casos con respuesta 0,
entrenamiento <- entrenamiento %>% filter(Q28 != 0) 
testeo <- testeo %>% filter(Q28 != 0)
#Filtramos los datos con valor de respuesta 0

# exploro Q28 en funcion de la edad.
plot(entrenamiento$age, entrenamiento$Q28, xlim = c(10,100))

# corro el modelo
modelo_q28 <- polr(as.factor(Q28) ~ age, data = entrenamiento)
summary(modelo_q28)

# predigo Q28 en funcion de la edad
predicciones_q28 <- predict(modelo_q28, testeo)
```

# 6

```{r}
# primero corremos el modelo
modelo_q9 <- polr( as.factor(Q9) ~ age, data = entrenamiento)
summary(modelo_q9)

#armo el dataframe de input
df_25 <- data.frame(age = c(25))
# hago una prediccion con el modelo
predicciones_q9 <- predict(modelo_q9, df_25, type = "p")

#Resultado del ejercicio, sumo la probabilidad para todas las opciones menores o iguales a 4
sum(predicciones_q9[0:5])
```

# 7

Defino la funcion de perdida

```{r}
funcion_perdida <- function(predicciones, variable_respuesta){
  #predicciones espera un vector con los valores de y sombrero
  #variable respuesta espera un vector con los verdaderos valores de y
  diferencia_absoluta <- abs(predicciones - variable_respuesta)
  perdida <- sum(diferencia_absoluta)/length(variable_respuesta)
  return(perdida)
}
```

Evaluamos la funcion con los dos modelos creados hasta ahora.

```{r}
# Primero hago las predicciones
predicciones_q9 <- predict(modelo_q9, testeo)

#Aplico la funcion de perdida
funcion_perdida(as.numeric(predicciones_q28), testeo$Q28)
funcion_perdida(as.numeric(predicciones_q9), testeo$Q9)
```

# 8

Primero armo y ajusto el modelo lineal

```{r}
# corro el modelo lineal
modelo_lineal_q28 <- lm(Q28 ~ age, data = entrenamiento)
summary(modelo_lineal_q28)
```

En segundo lugar, genero una funcion que tome las predicciones del modelo y las acote a los valores ordinales que puede tomar la variable de respuesta.

```{r}
pred_linear_fun <- function(predicciones){
  predicciones_redondeadas <- round(predicciones)
  #Redondeo a 1 si da menor que 1 y a 5 si da mayor que 5
  predicciones_ajustadas <- sapply(
    predicciones_redondeadas,
     function(x) ifelse(x < 1, 1, 
                        ifelse(x > 5, 5, x))
     )
  return(predicciones_ajustadas)
}
```

Implemento la funcion con las predicciones del modelo lineal

```{r}
predicciones_linear_q28 <- pred_linear_fun(predict(modelo_lineal_q28, testeo))
```

# 9

```{r}
# veo los resultados de las funciones de perdidas anterior
perdida_lineal_q28 <- funcion_perdida(
  predicciones_linear_q28,
  testeo$Q28
)
perdida_ordinal_q28 <- funcion_perdida(
  as.numeric(predicciones_q28),
  testeo$Q28
)

c(
  'Perdida Lineal' = perdida_lineal_q28,
  'Perdida Ordinal' = perdida_ordinal_q28
)
```

Parece ser que el modelo lineal presenta una menor funcion de perdida que el modelo de regresion ordinal.

# 10    

El modelo de regresion ordinal puede utilizar diferentes funciones de link por lo que vamos implementar una funcion que pruebe todas las posbiles funciones de link para modelo. 

```{r}
library(purrr)

varios_ordinales_fun <- function(formula){
  # corro varios modelos cada uno con su link function
link_functions <- c("logistic", "probit", "loglog", "cauchit")

varios_modelos <- link_functions %>%
  map(~ polr(as.formula(formula), data = entrenamiento, method = .x)) %>%
  map(~ funcion_perdida(
    as.numeric(predict(.x, testeo)), 
    testeo$Q28)
    )
  return(unlist(varios_modelos))
}

## Agregamos al modelo predictores que nos parecen que tienen sentido

# es posible que la edad pueda predecir si llevan una manta en la casa
modelo_edad <- varios_ordinales_fun('as.factor(Q28) ~ age')

# algunas religiones podrian utilizar mantas como parte de su vestimenta
modelo_edad_y_religion <- varios_ordinales_fun('as.factor(Q28) ~ age + religion')

# es posible que las personas que puntuan alto en "soy el mas feliz cuando estoy en la cama" tenga una relacion con la pregunta Q28
modelo_edad_religion_y_q10 <- varios_ordinales_fun('as.factor(Q28) ~ age + religion + Q10')

# Puede ser que edad y religion presenten una interaccion al predecir Q28. 
# Por ejemplo, quizas en algunas religiones personas mas grandes puntuen alto en Q28, no asi las personas mas jovenes.
modelo_religion_edad_q10_interaccion <- varios_ordinales_fun('as.factor(Q28) ~ age + religion + age:religion + Q10')

# evaluamos con un ANOVA si se justifica agregar un predictor al modelo
anova(
  polr(as.factor(Q28) ~ 1, data = entrenamiento), 
  polr(as.factor(Q28) ~ age, data = entrenamiento), 
  polr(as.factor(Q28) ~ age + religion, data = entrenamiento),
  polr(as.factor(Q28) ~ age + religion + Q10, data = entrenamiento),
  polr(as.factor(Q28) ~ age + religion + age:religion + Q10, data = entrenamiento)
)

# evaluamos la funcion de perdida y mostramos los resultados
data.frame(
 perdida = c(modelo_edad, modelo_edad_y_religion, modelo_edad_religion_y_q10, modelo_religion_edad_q10_interaccion),
 modelo = rep(c('edad','edad y religion', 'edad, religion y q10', 'religion, edad, q10 e interaccion'), each = 4)
) %>% group_by(modelo) %>% summarize(min(perdida))
```

# 11

Exploro algunas variables que nos parecen interesantes como posibles predictores de titulo universitario

```{r}
# genero
table(data$gender)
# es raro que aparezca el 0, ya que no esta en el codebook.txt,
# lo voy a sacar
entrenamiento <- entrenamiento %>% filter(gender != 0)
testeo <- testeo %>% filter(gender != 0)

# Q11	I did not work very hard in school.
hist(data$Q11)
table(data$Q11)
# saco a los datos con respuesta 0
entrenamiento <- entrenamiento %>% filter(Q11 != 0)
testeo <- testeo %>% filter(Q11 != 0)

# Q30	I think horoscopes are fun.
hist(data$Q30)
table(data$Q30)
# saco a los datos con respuesta 0
entrenamiento <- entrenamiento %>% filter(Q30 != 0)
testeo <- testeo %>% filter(Q30 != 0)

# Q32	I have thought about becoming a vegetarian.
hist(data$Q32)
table(data$Q32)
# saco a los datos con respuesta 0
entrenamiento <- entrenamiento %>% filter(Q32 != 0)
testeo <- testeo %>% filter(Q32 != 0)

```

Preparo el df para correr el modelo. 
En la pregunta "How much education have you completed?":

No tiene titulo universitario = 1=Less than high school, 2=High school

Tiene titulo universitario = 3=University degree, 4=Graduate degree

```{r}
# exploro la variable de educacion
hist(data$education)
table(data$education)
# saco a los datos con respuesta 0
entrenamiento <- entrenamiento %>% filter(education != 0)
testeo <- testeo %>% filter(education != 0)

# binarizo la variable de respuesta, siendo 0: no tienen titulo universitario, y 1: tiene titulo universitario
entrenamiento$education_universitaria<- ifelse(entrenamiento$education == 1 | entrenamiento$education == 2, 0, 1)
testeo$education_universitaria<- ifelse(testeo$education == 1 | testeo$education == 2, 0, 1)
```


Corro el modelo y calculo el error segun la exactitud

```{r}
mod_log <- glm(education_universitaria ~ 
                  gender +
                  Q11 +
                  Q30+
                  Q32+
                  age,
           family=binomial(link="logit"), 
           data = entrenamiento)

summary(mod_log)

predicciones_mod_log <- predict(mod_log, testeo, type="response")
hist(predicciones_mod_log)

predicted.classes <- ifelse(predicciones_mod_log > 0.5, 1, 0)

# veo exactitud
mean(predicted.classes == testeo$education_universitaria)
```

# 12

En primer lugar generamos varias muestras aleatorias de nuestro dataframe, con distinto n pero sin repeticion. Para eso armamos una distribucion uniforme entre los dos rangos de valores que consideramos apropiados. Vamos a usar 1000 muestras a partir de un rango de entre 50 y 5000 datos. 

Armamos para esto una funcion la cual, en cada iteracion saca una muestra de la distribucion uniforme que definimos y seleciona una muestra aleatoria de nuestros datos con ese muestral. 

```{r}
random_sampling_fun <- function(){
  random_n <- runif(1,50,5000)
  datos_sampleados <- entrenamiento %>% dplyr::slice_sample(. ,n = random_n)
  return(datos_sampleados)
}
```

Generamos otra funcion que va a utilizar los datos creados por la funcion `random_sampling_fun` y los va a usar para ajustar un modelo de regresion logistica calculando la exactitud. La exactitud siempre se calcula sobre el conjunto de testeo que tiene un tama√±o fijo. De esta manera la funcion otorga un vector de dos valores, uno indicando la cantidad de datos utilizados y otro indicando el valor de exactitud obtenido.

```{r}
random_fit_predict <- function(){
  datos_muestrales <- random_sampling_fun()
  n_muestral <- nrow(datos_muestrales)
  #Aca va el modelo de regresion logistica
  modelo <- glm(education_universitaria ~ 
                  gender +
                  Q11 +
                  Q30+
                  Q32+
                  age,
           family=binomial(link="logit"), 
           data = datos_muestrales)
  
  #Aca va la funcion de calculo de exactitud
  exactitud <- mean(
    ifelse(predict(modelo, testeo, type="response") > 0.5, 1, 0) == testeo$education_universitaria
    )
  resultado <- c(n_muestral, exactitud)
  return(resultado)
}
```

Una vez definidas ambas funciones las integramos en un loop que corra 1000 veces para obtener 1000 pares de combinaciones de tama√±o muestral y exactitud.

```{r}
multiple_log <- replicate(1000, random_fit_predict())
```

Posteriormente creamos un dataframe de los resultados usando la matriz transpuesta. 

```{r}
multiple_log_df <- as.data.frame(
  t(multiple_log)
)
colnames(multiple_log_df) <- c('N', 'Exactitud')
```

Graficamos el resultado de la exactitud en funcion del N y le aplicamos un ajuste local para tratar de ver patrones.  

```{r}
ggplot(data = multiple_log_df, aes(x = N, y = Exactitud)) +
  geom_point() + geom_line() + geom_smooth(span = 0.2, method = 'loess')
```
Pareceria que la exactitud sube con el N unicamente para valores peque√±os, menores a 200 aproximadamente pero despues converge hacia un determinado valor perdiendo variabilidad con valores de tama√±o de muestra mas grandes. 


```{r}
library(betareg)
beta_unif <- betareg::betareg(Exactitud ~ N, data = multiple_log_df)
summary(beta_unif)
```

La regresion beta nos arroja un coeficiente negativo para la asociacion el N.

Podriamos probar ahora con usar una grilla de valores de tama√±o de muestra que se vaya incrementando desde 50 a 5000, con una longitud total de 1000 valores como en el caso anterior.

```{r}
grilla_n <- seq(50,5000, length.out = 1000)
```

El problema es que la funcion `random_sampling_fun` tiene ya establecido usar `runif` por lo que habria que modificarla para poder usar la funcion `random_fit_predict` con la grilla. Vamos a modificarla de manera que tome como argumento una funcion o valor numerico que defina el tama√±o muetral. Tambien modificamos la funcion `random_fit_predict` para que pueda tomar el argumento que se le va a suministrar a `random_sampling_fun`.

```{r}
random_sampling_fun <- function(random_fun){
  random_n <- random_fun
  datos_sampleados <- entrenamiento %>% dplyr::slice_sample(. ,n = random_n)
  return(datos_sampleados)
}

random_fit_predict <- function(random_fun){
  datos_muestrales <- random_sampling_fun(random_fun)
  n_muestral <- nrow(datos_muestrales)
  #Aca va el modelo de regresion logistica
  modelo <- glm(education_universitaria ~ 
                  gender +
                  Q11 +
                  Q30+
                  Q32+
                  age,
           family=binomial(link="logit"), 
           data = datos_muestrales)
  
  #Aca va la funcion de calculo de exactitud
  exactitud <- mean(
    ifelse(predict(modelo, testeo, type="response") > 0.5, 1, 0) == testeo$education_universitaria
    )
  resultado <- c(n_muestral, exactitud)
  return(resultado)
}
```


Implementamos ahora la funcion con la grilla

```{r}
multiple_log_grilla <-  sapply(grilla_n, random_fit_predict)
```

Igual que hicimos en el caso anterior armamos un dataframe con la matriz transpuesta.

```{r}
multiple_log_grilla_df <- as.data.frame(t(multiple_log_grilla))
colnames(multiple_log_grilla_df) <- c('N', 'Exactitud')
```

Graficamos la exactitud en funcion del N.

```{r}
ggplot(data = multiple_log_grilla_df, aes(x = N, y = Exactitud)) +
  geom_point() + geom_line() + geom_smooth(span = 0.2, method = 'loess')
```

En este caso no pareceria haber una pendiente negativa evidente como en el anterior pero vemos que el tama√±o de la muestra no mejora la exactitud salvo con los valores mas bajos. 
Ajustamos entonces la regresion beta.

```{r}
beta_grilla <- betareg::betareg(Exactitud ~ N, data = multiple_log_grilla_df)
summary(beta_grilla)
```
El coeficiente igual sigue siendo negativo. 

Podemos repetir el procedimiento de usar una distribucion uniforme sobre el tama√±o muestral pero esta vez teniendo una cota superior mucho mas chica. 

```{r}
multiple_small_n <- replicate(1000, 
          random_fit_predict(runif(1,30,200))
          )
multiple_small_n_df <- as.data.frame(t(multiple_small_n))
colnames(multiple_small_n_df) <- c('N', 'Exactitud')
```

Graficamos

```{r}
ggplot(data = multiple_small_n_df, aes(x = N, y = Exactitud)) +
  geom_point() + geom_line() + geom_smooth(span = 0.2, method = 'loess')
```

Aca pareceria haber una relacion positiva entre el tama√±o muestral y la exactitud. 

```{r}
beta_small_n <- betareg(Exactitud ~ N, data = multiple_small_n_df)
summary(beta_small_n)
```

Si usamos este modelo para generar predicciones para distintos N podemos compararlo con los resultados anteriores. Armamos un data frame con predicciones de este ultimo modelo beta para un tama√±o de muestra que vaya de 500 a 5000.

```{r}
predicciones_beta_df <- data.frame(
  Exactitud = predict(beta_small_n, data.frame(N = seq(50,5000, 50))),
  N = seq(50, 5000, 50)
)
```

Graficamos comparando con los anteriores resultados.

```{r}
rbind(predicciones_beta_df, multiple_log_grilla_df, multiple_log_df) %>% 
  mutate(
    data_origin = rep(
      c('Predicciones', 'Grilla', 'Uniforme'),
      c(nrow(predicciones_beta_df), nrow(multiple_log_grilla_df), nrow(multiple_log_df))
    )
  ) %>%
  ggplot(aes(x = N, y = Exactitud, color = data_origin)) +
  geom_point() + geom_line()
```

El modelo predice bien dentro del rango de datos que usamos para la regresion beta es decir tama√±os muestrales hasta 200 pero despues generaliza muy mal a medida que el n aumenta. 

```{r}
predicciones_beta_df$N[which.min(abs(0.9 - predicciones_beta_df$Exactitud))]
```
Podemos comprobar el modelo que armamos para una exactitud de 0.9 pero vemos que esa exactitud luego no se cumple cuando contamos con esa cantidad de datos. 
