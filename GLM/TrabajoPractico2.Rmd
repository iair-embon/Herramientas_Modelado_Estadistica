---
title: "Trabajo Practico 2"
author: "Iair Embon & Alejandro Ramos Usaj"
date: '2022-06-18'
output: html_document
---


#1 

```{r}
# cargo los datos
root <- rprojroot::is_rstudio_project
basename(getwd())

data <- read.csv(root$find_file("GLM/encuesta.csv"))

# divido en entrenamiento y testeo 
library(dplyr)

entrenamiento <- data %>%
  slice_sample(prop = 0.8)

testeo <- data %>%
  slice(-pull(entrenamiento,X))

```

#2 

>Llamamos Q a la pregunta Q28

#3

>El problema teorico de usar una regresion lineal es que la veriable de respuestas Y no es escalar, es decir, las distancias entre cada unidad no son equivaletes y la respuesta Y no es continua. 
Segun Agresti (2015), el modelo de regresion lineal podria utilizarse para ver que variables afectan Y pero presentaria algunas limitaciones. En primer lugar si la respuesta es verbal en lugar de numerica asignar valores numericos a categorias como 'Totalmente en desacuerdo' o 'Totalmente de acuerdo' es muy arbitrario porque se podria decir que uno de los extremos representa el 1 y el otro el 5 o uno de los extremos representa el 1 y el otro el 10 o el 7 o cualquier otro numero. En segundo lugar si asumimos que las respuestas ordinales responden a una variable continua latente, distintos valores de la variable latente puede corresponderse con un mismo valor de la variable latente siendo que cualquier valor dentro del rando de dos umbrales va a corresponderse con el mismo valor ordinal aunque tengan distinto valor de la variable latente. En tercer lugar el modelo lineal comun no otorga probabilidades estimadas a cada categoria ordinal por lo que no seria claro como ordinalizar una prediccion numerica continua. Por ultimo la variabilidad de los datos no es constante para la variable de respuesta, una variable ordinal tiene poca variabilidad cuando dados los valores de la covariada la variable de respuesta se ubica en los extremos de la escala ordinal lo cual esta relacionado con el hecho de que los umbrales para los extremos no estan acotados en la distribucion de la variable latente. 


>El porblema teorico al momento de usar una regresion multinomial para estos datos seria que no aprovecharia la caracteristica ordinal de la variable de respuesta. Un modelo ordinal tiene una ordenada dada por la categoria ordinal pero los coeficientes son los mismos independientemente de la categoria ya que se asume que el efecto de las covariadas es el mismo para cada probabilidad acumulada. De esta manera un modelo ordinal utilizaria muchos menos parametros, ya que los coeficientes no dependen de cada categoria como sucede en el modelo multinomial porque no se puede utilizar una estructura de probabilidad acumulada como la que se trabaja en un modelo ordinal. 

#4

>Este modelo supone que las respuestas Y corresponden a una variable del tipo ordinal con J categorias. A diferencia del modelo multinomial clasico donde se quiere calcular, en ultima instancia, la probabilidad de pertenecer a cada categoria. En este caso aprovechamos la estructura ordinal asumiendo que existe una variable latente que desconocemos a partir de la cual con determinados umbrales numericos se construyeron las respuestas ordinales observadas. La probabilidad de que la respuesta y sea igual a la categoria ordinal j puede pensarse como una probabilidad acumulada. Lo que se intenta modelar entonces es la probabilidad acumulada de que la respuesta sea menor o igual a j dado determinado efecto de las covariadas y determinados puntos de corte, ambos parametros a estimar. Se puede repensar entonces la probabilidad de que la respuesta sea menor o igual a la categoria j como la probabilidad de que el valor de la variable latente sea menor o igual al punto de corte de la categoria j es decir la funcion de probabilidad acumulada. Si la funcion de probabilidad acumulada asumimos que es la logistica standard entonces la funcion de link (que es la inversa de probabilidad acumulada) es el logit y si asumimos que es la acumulada de la normal entonces utilizamos como link la funcion probit. En este modelo, la intercept es diferente para cada J, mientras que el slope es el mismo.

#5

```{r}
library(MASS)
library(tidyverse)

# exloro la variable age
hist(entrenamiento$age)
# hay una edad que tiene 353 a√±os, y uno de 99. quizas es mejor sacar esos dos

# exploro Q28
hist(entrenamiento$Q28)
table(entrenamiento$Q28)
# es raro porque hay 24 casos con respuesta 0,

# exploro Q28 en funcion de la edad.
plot(entrenamiento$age, entrenamiento$Q28, xlim = c(10,100))

# corro el modelo
m <- polr(as.factor(Q28) ~ age, data = entrenamiento, method = "logistic")
summary(m)

# predigo Q28 en funcion de la edad
predicciones <- predict(m, testeo)

```

#6

```{r}
# primero corremos el modelo
m2 <- polr( as.factor(Q9) ~ age, data = entrenamiento, method = "logistic")
summary(m2)

# hago las predicciones con el modelo de testeo
predicciones2 <- predict(m2, testeo)
hist(as.numeric(predicciones2))
table(predicciones2)

# estimo la probabilidad de que una persona de 25 anos este al menos de acuerdo con la frase "me gustan las armas"

# viendo las predicciones2, es claro que la probabiliad estimada es de 1
# el codigo para corroborarlo seria el siguiente
predicciones3 <- predict(m2, testeo, type = "p")

max.prob <- rep(NaN, nrow(testeo))

for (i in 1:length(max.prob)) {
     index.max <- which.max(predicciones[i,])
     max.prob[i] <- index.max[[1]]}

table(max.prob)

```


#7

```{r}

# vamos a elegir una link function basados la que tenga un resultado menor en la funcion de perdida

# corro varios modelos cada uno con su link function
link_functions <- c("logistic", "probit", "loglog", "cauchit")

varios_modelos <- link_functions %>%
  map(
  ~ polr(as.factor(Q28) ~ age, data = entrenamiento, method = .x)
)

# realizo predicciones en el df de testeo y saco la funcion de perdida del ejercicio 7
funcion_de_perdida <- rep(NaN, length(varios_modelos))

for (i in 1:length(varios_modelos)) {
  predicciones <- predict(varios_modelos[[i]], testeo)
  funcion_de_perdida[i] <- sum(abs(as.numeric(testeo$Q28) - as.numeric(predicciones)))/nrow(testeo)
}

index_min <- which.min(funcion_de_perdida)

# la link function que tiene menor error segun la funcion de perdida implementada es:
link_functions[index_min]
```








