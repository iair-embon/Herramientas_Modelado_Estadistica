---
title: "Trabajo Practico 3"
author: "Alejandro Ramos Usaj y Iair Embon"
date: '2022-07-07'
output: html_document
---
Cargo librerias que vamos a utilizar
```{r}
library(tidyverse)
library(mgcv)
```

Cargo los datos
```{r}
root <- rprojroot::is_rstudio_project
basename(getwd())

titles_train <- read.csv(root$find_file("Mixtos/titles_train.csv"))
credits_train <- read.csv(root$find_file("Mixtos/credits_train.csv"))
```

# 1

Primero tengo que normalizar la base de datos de entrenamiento que tiene muchos generos metidos en una sola columna. Queremos que cada genero sea una sola columna y que tenga un valor de 1 indicando si esa fila pertenece a ese genero y 0 de otra manera. 

Para esto en primer lugar eliminamos de las filas con el genero de las peliculas a todos los caracteres que no corresponden con letras o comas. De esta manera deberiamos quedarnos con una estructura que sea "genero1, genero2, ..., generoN". De ahora en mas comprobamos el procedimiento extrayendo 10 datos aleatoriamente del dataframe resultante posterior a la manipulacion.
```{r}
titles_train %>% 
  mutate(genres = str_replace_all(genres,"[^A-Za-z,]","")) %>%
  slice_sample(n = 10) %>%
  pull(genres)
```

A continuacion usamos la funcion de `separate_rows` para separar los generos por coma de manera que cada uno sea una fila nueva. 
```{r}
titles_train %>% 
  mutate(genres = str_replace_all(genres,"[^A-Za-z,]","")) %>% 
  separate_rows(genres, sep = ',') %>% 
  slice_sample(n = 10) %>%
  select(title, genres)
```

Proximamente generamos una columna dummy nueva con todos valores de 1 para usar como valores cuando pasemos el dataframe a formato wide. Asimismo filtramos aquellas filas que quedaron sin ningun genero (sin caracteres) como consecuencia de la funcion `separate_rows`.
```{r}
titles_train %>% 
  mutate(genres = str_replace_all(genres,"[^A-Za-z,]","")) %>% 
  separate_rows(genres, sep = ',') %>% 
  mutate(dummy = 1) %>% filter(genres != '') %>% 
  slice_sample(n = 10) %>%
  select(title, genres, dummy)
```

Por ultimo vamos a usar la funcion `pivor_wider` para convertir el dataframe de formato long (como esta ahora, con filas repetidas para distintos titulos) a formato wide donde cada genero corresponda a una columna con valores dados por la columna dummy. 
```{r}
titles_train %>% 
  mutate(genres = str_replace_all(genres,"[^A-Za-z,]","")) %>% 
  separate_rows(genres, sep = ',') %>% 
  mutate(dummy = 1) %>% filter(genres != '') %>% 
  pivot_wider(names_from = genres, values_from = dummy) %>% 
  slice_sample(n = 10) %>%
  select(title, comedy:sport)
```

Finalmente reemplazamos aquellos valores que quedaron como `NA` con un 0 indicando que ese genero no pertenece a ese titulo y escribimos todo el procedimiento anterior en un solo bloque. 
```{r}
titles_train_trans <- titles_train %>% 
  mutate(genres = str_replace_all(genres,"[^A-Za-z,]","")) %>% 
  separate_rows(genres, sep = ',') %>% 
  mutate(dummy = 1) %>% filter(genres != '') %>% 
  pivot_wider(names_from = genres, values_from = dummy) %>% 
  mutate(across(comedy:sport, ~ replace_na(.x, 0))) 
```

Por ultimo podria ser interesante tener una columna que cuente cuantos generos tiene un determinado titulo y para esto vamos a agregar una columna nueva sumando los 1 para todas las columnas correspondientes a los distintos generos. 
```{r}
titles_train_trans <- titles_train_trans %>% mutate(cant_genres = rowSums(across(comedy:sport)))
```

Solo falta normalizar la columna correspondiente a los paises encargados de la produccion. Sin embargo hay demasiados paises involucrados, muchos mas que en el caso de los generos lo que nos dejaria con demasiadas columnas con muchos valores en 0. 
```{r}
titles_train_trans <- titles_train_trans %>% 
  mutate(production_countries = str_replace_all(production_countries,"[^A-Za-z,]","")) %>% 
  mutate(
    production_countries = strsplit(production_countries, ','),
    production_countries = lapply(production_countries, sort),
    production_countries = as.character(production_countries)
  ) %>%
  unnest(cols = production_countries) %>%
  mutate(production_countries = str_replace_all(production_countries,"[^A-Z,]",""))
```


## a)

Exploramos el genero en base al puntaje imdb
```{r}
titles_train %>% 
  mutate(genres = str_replace_all(genres,"[^A-Za-z,]","")) %>% 
  separate_rows(genres, sep = ',') %>% filter(genres != '') %>%
  ggplot(
    aes(x = genres, y = imdb_score)
  ) +
    geom_boxplot()+
  theme(axis.text.x = element_text(angle = 45, hjust=1))
```
## b)

Exploramos el puntaje a lo largo de los años
```{r}
titles_train %>% 
  mutate(genres = str_replace_all(genres,"[^A-Za-z,]","")) %>% 
  separate_rows(genres, sep = ',') %>% filter(genres != '', !is.na(imdb_score)) %>%
  ggplot(aes(x= release_year, y=imdb_score)) +
    geom_line() +
    geom_point()
   
```

Ahora exploramos el puntaje a lo largo de los años teniendo en cuenta el genero
```{r}
titles_train %>% 
  mutate(genres = str_replace_all(genres,"[^A-Za-z,]","")) %>% 
  separate_rows(genres, sep = ',') %>% filter(genres != '', !is.na(imdb_score)) %>%
  ggplot(aes(x=release_year, y=imdb_score, color = genres)) +
    geom_line() +
    facet_wrap("genres") +
   theme(axis.text.x = element_text(angle = 45, hjust=1))
   
```

## c)

Para explorar lo pedido, se combinan el dataframe que contiene la informacion de las personas que ocupan rol de director o actor, y el dataframe que contiene la informacion del puntaje imdb, utilizando la columna llave "id". Luego se imprimen los 10 actores o directores que mejores y peores puntajes tienen.
```{r}
# Primero combino credits_train con titles_train utilizando la columna "id"
titulos_creditos_combinados<- inner_join(titles_train, credits_train, by = "id")

# Veo los 10 actores o directores que mejores puntajes tienen
titulos_creditos_combinados %>%
  group_by(titulos_creditos_combinados$person_id) %>%
  summarise(mean = mean(imdb_score)) %>%
  top_n(10)

# Veo los 10 actores o directores que peores puntajes tienen
titulos_creditos_combinados %>%
  group_by(titulos_creditos_combinados$person_id) %>%
  summarise(mean = mean(imdb_score)) %>%
  top_n(-10)

```

## d)

Se tomara la columna imdb_votes como una medida de popularidad, suponiendo que la cantidad de votos estaria asociado con la cantidad de personas que ven un film determinado.
Pareceria ser que la cantidad de votos y el puntaje esta asociado de manera postiva.
```{r}
titles_train %>%
  ggplot(aes(imdb_votes, imdb_score)) +
    geom_point()

# ahora me fijo en los que tienen menos de 250000 votos
titles_train %>%
  ggplot(aes(imdb_votes, imdb_score)) +
    geom_point() +
    xlim(0,250000)
```

## e)

```{r}
library(tidytext)
```

Primero armo un nuevo dataframe con las palabras tokenizadas de los titulos de las peliculas.

```{r}
data("stop_words")

token_titles <- titles_train %>%
  #Convierto los titulos de las peliculas en string porque esta como factor
  mutate(title = as.character(title)) %>%
  #Saco unicamente las columnas que me interesan que son el id, el titulo y el puntaje.
  select(id, title, imdb_score) %>%
  #Tokenizo la columna del titulo
  unnest_tokens(palabras, title) %>% 
  #Agrupo por id
  group_by(id) %>%
  #Calculo la posicion de cada palabra en el titulo aprovechando que agrupe por id
  mutate(word_number = row_number()) %>%
  #Elimino las stopwords
  filter(!palabras %in% stop_words$word) %>%
  ungroup()
```

Calculo ahora la mediana de puntaje para cada palabra y me quedo con aquellas palabras que aparezcan mas de una determinada cantidad de veces. Para definir esto ultimo primero miramos un histograma en escala logaritmica del eje y para ver mejor el patron.

```{r}
token_titles %>% count(palabras) %>% 
  ggplot(aes(x = n)) + 
  geom_histogram() +
  scale_y_log10()
```

Vamos a suponer que una palabra tuvo que haber aparecido por lo menos 15 veces para ser contabilizada con lo cual filtramos las palabras con menos de 15 apariciones. Luego de lo cual podemos filtrar los titulos que no tienen puntaje de imdb, agrupamos por palabra y calculamos la mediana para graficar.

```{r}
mediana_titles <- token_titles %>%
  filter(
    palabras %in% (token_titles %>% count(palabras) %>% filter(n >= 15) %>% pull(palabras))
  ) %>%
  filter(!is.na(imdb_score)) %>%
  group_by(palabras) %>%
  summarise(mediana = median(imdb_score))

mediana_titles %>%
  ggplot(aes(x = reorder(palabras, -mediana), y = mediana)) +
  geom_segment(aes(x = reorder(palabras, -mediana), xend = reorder(palabras, -mediana), y = 5, yend = mediana)) +
  geom_point() +
  ylab('Median score') + xlab('Words') +
  coord_flip()
```

Quedaron algunas stopwords de otros idiomas como el español que no fueron captadas por el dataframe de stopwords que utilizamos. Para eliminarlas habria que utilizar alguna referencia de stopwords con mayor representacion multilinguistica. 

## Exploramos otras variables que nos interesan

Exploro type y el puntaje imdb
```{r}
table(titles_train$type)

titles_train %>% 
  filter(!is.na(imdb_score)) %>%
  ggplot(aes(x=type, y=imdb_score)) + 
    geom_boxplot()
```

Exploro type y el puntaje imdb, segun el genero
```{r}
titles_train %>% 
  mutate(genres = str_replace_all(genres,"[^A-Za-z,]","")) %>% 
  separate_rows(genres, sep = ',') %>% 
  filter(genres != '', !is.na(imdb_score)) %>%
  ggplot(aes(x=type, y=imdb_score, fill= genres)) + 
    geom_boxplot()
```

Exploro el puntaje imdb en relacion a los paises
```{r}
titles_train_trans %>%
  mutate(production_countries = str_replace_all(production_countries,"[^A-Za-z,]","")) %>% 
  separate_rows(production_countries, sep = ',') %>% 
  filter(production_countries != '', !is.na(imdb_score)) %>%
  mutate(production_countries = fct_lump_n(production_countries, 10, other_level = "Otros")) %>%
  ggplot(aes(x=production_countries, y=imdb_score)) + 
    geom_boxplot()
```
Exploro el puntaje imdb por pais en el tiempo
```{r}
titles_train_trans %>%
  mutate(production_countries = str_replace_all(production_countries,"[^A-Za-z,]","")) %>% 
  separate_rows(production_countries, sep = ',') %>% 
  filter(production_countries != '', !is.na(imdb_score)) %>%
  mutate(production_countries = fct_lump_n(production_countries, 10, other_level = "Otros")) %>%
  ggplot(aes(x=release_year, y=imdb_score, color = production_countries)) +
    geom_line() +
    facet_wrap("production_countries") +
   theme(axis.text.x = element_text(angle = 45, hjust=1))
   
```
Exploro la variable runtime en relacion al puntaje imdb
```{r}
library(ggExtra)

p <- titles_train_trans %>%
  filter( !is.na(imdb_score)) %>%
  ggplot(aes(x=runtime, y=imdb_score)) +
      geom_point() +
      theme(legend.position="none")

ggMarginal(p, margins = 'both', color="purple", size=4)
```
Exploro la variable seasons en relacion al puntaje imdb
```{r}
library(ggExtra)

p <- titles_train_trans %>%
  filter(!is.na(imdb_score), !is.na(seasons)) %>%
  ggplot(aes(x=seasons, y=imdb_score)) +
      geom_point() +
      theme(legend.position="none")

ggMarginal(p, margins = 'both', color="purple", size=4)
```

Exploro el puntaje imdb en relacion al age_certification
```{r}
titles_train_trans %>%
  filter(!is.na(imdb_score),!is.na(age_certification)) %>%
  ggplot(aes(x=age_certification, y=imdb_score)) + 
    geom_boxplot()
```

# 2

Agarro el df que tenia los paises en una coluna, y agrupo todos los que son menores de 5 en la categoria "otros"
```{r}
titles_train_trans_OtrosPaises <- titles_train_trans %>%
  filter(production_countries != '',!is.na(imdb_score)) %>%
  mutate(production_countries = fct_lump_min(production_countries, 5, other_level = "Otros"))
```

## a)

Corro un modelo lineal para predecir el puntaje de imdb con production_countries. El modelo es de efectos fijos.
```{r}
m_EfectosFijos <- lm(imdb_score ~ production_countries, data = titles_train_trans_OtrosPaises)

summary(m_EfectosFijos)
```

## b)

Corro un modelo lineal multiple mixto para predecir el puntaje de imdb con production_countries. El modelo tiene la intercept como efecto fijo, mas un efecto aleatorio por production_countries.
```{r}
library(lme4)
m_InterceptAleatoria <- lmer(imdb_score ~ (1|production_countries), data = titles_train_trans_OtrosPaises)

summary(m_InterceptAleatoria)
ranef(m_InterceptAleatoria)
```

## c)

Uilizando el script realizado por el profesor en clase, grafico las intercepts fijas y aleatorias 
```{r}
library(ggrepel)
# calculo en numero de casos de production_countries
n_casos_production_countries = titles_train_trans_OtrosPaises %>% 
  group_by(production_countries) %>% 
  summarise(num_cases = n()) %>% 
  pull(num_cases)

# Obtengo intercepts aleatorios con fit_3
lmm_intercepts = ranef(m_InterceptAleatoria)[['production_countries']][,1] +fixef(m_InterceptAleatoria)[['(Intercept)']]

# Obtengo intercepts fijos con fit_1
fixed_intercepts = as.array(m_EfectosFijos$coefficients) 
# le sumo la intercept a cada beta del modelo fijo para que esten mas cercanos a las intercept del modelo mixto y los pueda comparar
fixed_intercepts = c(fixed_intercepts[1],
                     as.array(m_EfectosFijos$coefficients)[2:length(fixed_intercepts)]+fixed_intercepts[1])

# Grafico efectos fijos vs efectos aleatorios, incluyendo el tamano de muestra como size
tibble(lmm = lmm_intercepts, 
       fixed = fixed_intercepts, 
       num_cases = n_casos_production_countries,
       pr_count = sort(unique(titles_train_trans_OtrosPaises$production_countries))) %>%
  mutate(rn = row_number()) %>% 
  pivot_longer(c(fixed, lmm)) %>% 
  ggplot(aes(x = rn, y = value, label= pr_count, color = name)) +
  geom_point(aes(size = num_cases), alpha = 0.5) +
  geom_text_repel(aes(label = pr_count)) +
  theme_bw() +
  theme(legend.position = 'bottom')

## En el grafico se puede ver que los paises que tienen una mayor cantidad de casos los afecta menos si se utiliza un modelo de efectos aleatorios o un modelo de efectos fijos. Cuando los paises tienen pocos casos, desde el modelo de efectos aleatorios, se acercan mas hacia la media, en comparacion con lo que hace con esos mismos paises el modelo de efectos fijos. 
```

# 3

## a)

Agregamos al modelo del item 2b (el de la intercept aleatoria por paises) el predictor release_year, y luego decidimos si valio la pena utilizando anova 
```{r}
# corro el modelo
m2_InterceptAleatoria_release_year <- lmer(imdb_score ~ release_year + (1|production_countries), data = titles_train_trans_OtrosPaises)

# veo los resultados
summary(m2_InterceptAleatoria_release_year)
ranef(m2_InterceptAleatoria_release_year)

# decido si vale la pena sumar al modelo la variable release_year usando anova
anova(m_InterceptAleatoria,
      m2_InterceptAleatoria_release_year)

# basado en el resultado del anova, pareceria que si valdria la pena agregar release_year al modelo del item 2b
```

## b)

Separo en datos de entrenamiento y de testeo y comparo m_InterceptAleatoria y m2_InterceptAleatoria_release_year y selecciono el que tenga un menor error cuadratico medio en los datos del testeo.
```{r}
# divido en datos de entrenamiento y de testeo
entrenamiento <- titles_train_trans_OtrosPaises %>%
  slice_sample(prop = 0.8)

testeo <- titles_train_trans_OtrosPaises %>%
  slice(-pull(entrenamiento,X))

# entreno los modelos en la data de entrenamiento

m_InterceptAleatoria_entrenamiento <- lmer(imdb_score ~ (1|production_countries), data = entrenamiento)

m2_InterceptAleatoria_release_year_entrenamiento <- lmer(imdb_score ~ release_year + (1|production_countries), data = entrenamiento)

# predigo usando la data de testeo con el primer modelo
predicciones_m <- predict(m_InterceptAleatoria_entrenamiento, testeo)

# predigo usando la data de testeo con el segundo modelo
predicciones_m2 <- predict(m2_InterceptAleatoria_release_year_entrenamiento, testeo)

# creo una funcion que calcule el error cuadratico medio
error_cuadratico_medio <- function(y_predic, y){
  error <- mean((y - y_predic)**2)
  return(error)
}

error_cuadratico_medio_m <- error_cuadratico_medio(predicciones_m, testeo$imdb_score)
error_cuadratico_medio_m2 <- error_cuadratico_medio(predicciones_m2, testeo$imdb_score)
```

## c) 

Mientras que el anova muestra una significancia estadistica al agregar el predictor release_year con respecto al modelo que no tiene este predictor, el error cuadratico medio al comparar ambos predictores no pareciera ser abismal. El anova mide como impacta el hecho de agregar un predictor (release_year) en los residuales. En este caso, impacto de manera significativa. Sin embargo, el error cuadratico medio, que evalua que tan bien predice el modelo, pareciera no variar en gran medida al agregar el predictor "release_year". El error cuadratico medio es una metrica predictiva. Ademas el anova supone una cierta distrubicion, con ciertos grados de libertad, es decir, es una metrica parametrica. A diferencia del error cuadratico medio, que es no parametrico.

-----

# 4)

## a)

```{r}
#Definimos los posibles valores de k para comparar
k_values <- c(1,2,3,5,10,20,50)
library(mgcv)

#Ajusto el modelo con cada valor del vector de posibles valores de k y voy guardando en una lista
gam_fits <- lapply(
  k_values,
  function(x) gam(imdb_score ~ s(release_year, bs = 'cr', k = x), data = titles_train_trans)
)

#Armo una lista con las predicciones
lista_predicciones <- lapply(spam, 
                function(x) predict(x, titles_train_trans)
                )

#Combino la lista en un solo dataframe
df_predicciones <- tibble(prediccion = unlist(lista_predicciones)) %>% 
  mutate(
    k = rep(k_values, each = nrow(titles_train_trans)),
    covariada = rep(titles_train_trans$release_year, length(k_values))
    )

#Grafico los datos de entrenamiento y las predicciones para cada valor de k
df_predicciones %>%
  ggplot(
    aes(x = covariada, y = prediccion, color = as.factor(k))
         ) +
  geom_line() +
  xlab('Release Year') + ylab('Prediccion') +
  scale_color_discrete('Valor de k')
```
Cuando armamos el modelo los niveles de k mas bajos no lograron ajustarse correctamente por lo que la funcion elevo k al nivel minimo y por eso no se ven diferencias con las curvas de los valores mas bajos. 


## b)

Generamos la particion

```{r}
#Planto la semilla
set.seed(1234)

#Separo en entrenamiento y testeo
gam_train <- titles_train_trans %>% 
  slice_sample(prop = 0.8)
gam_test <- titles_train_trans %>%
  filter(
    !id %in% gam_train$id
  )
```

Calculo el RMSE para cada caso

```{r}
rmse_gam <- lapply(
  k_values,
  function(x) gam(imdb_score ~ s(release_year, bs = 'cr', k = x), data = gam_train) %>%
    predict(gam_test) %>%
    tibble(predicciones = .) %>% 
    mutate(
      true_value = gam_test %>% pull(imdb_score),
      error_cuadratico = (predicciones - true_value)^2
           ) %>%
    summarise(
      rmse = sqrt(mean(error_cuadratico, na.rm = T))
    )
) %>% 
  bind_rows() %>%
  mutate(k = k_values)
```
Ahora simplemente visualizamos

```{r}
rmse_gam %>%
  ggplot(aes(x = k, y = rmse)) +
  geom_point() + geom_line()
```
Igual que antes los valores k mas bajos (menores a 3) terminan llevandose a un mismo valor minimo de k por la funcion por lo que no hay diferencias en esos RMSE. Despues de visualizar calculamos el valor que minimiza.

```{r}
rmse_gam$k[which.min(rmse_gam$rmse)]
```

# 5)

```{r}
library(rsample)
set.seed(4567)
```

Para encontrar el k optimo de cada modelo vamos a utilizar un approach similar al del ejercicio 4 utilizando la misma division de datos.
En este caso sin embargo ponemos todo dentro de una funcion para correrlo con los distintos modelos seleccionados. Necesitamos entonces una funcion que ajuste el modelo en los datos de entrenamiento variando el valor de k y compare las predicciones con el dataset de testeo para hallar el k optimo. Cada funcion puede tener distintos niveles del valor k por lo cual no necesariamente la combinacion optima de valores de k para modelos con mas de una variable es aquella donde k es igual en todos los casos. Sin embargo la complejidad con la crece el espacio de parametros posibles a explorar es la longitud de la grilla de posibles valores de k elevado a la cantidad de covariadas que tenga el modelo. Sin embargo la mayoria de las variables que nos interesan no son continuas por lo que unicamente tenemos que estimar este parametro para 2 variables que son `release_year` y `runtime`. 

```{r}
grilla_k <- seq(1,100)


k_optimo_finder <- function(modelo_gam, potenciales_k){
  
  #Primero se itera por todos los potenciales valores de k
  map(potenciales_k,
      ~ gam( #Genero una cantidad de modelos igual a la cantidad de k candidatos
        as.formula(modelo_gam), 
        family = betar(link='logit'), #Usamos la familia beta porque el rango de la variable de respuesta esta restringido
        data = gam_train) 
  ) %>%
    map(
      ~ predict(.x, gam_test) - gam_test$imdb_score #Calculo la diferencia con la prediccion para cada potencial k sobre el conjunto de testeo
    ) %>%
    map( #Calculo el RMSE para ese k
      ~ sqrt(
      mean(.x^2, na.rm = T)
           )
    ) %>%
    unlist() %>% #Convierto la lista en un vector
    which.min() %>% #Calculo el indice del valor k optimo
    potenciales_k[.] #
}
```

Asignamos como factor las variables que vayamos a usar en el GAM. Tambien transformo la variable de respuestas para pasarla a escala [0,1] dado que los puntajes no pueden superar el valor de 0 o de 10 con lo cual dividiendo por el maximo llevamos la escala a este rango y podemos ajustar un modelo de la familia beta aprovechando el rango acotado de los datos. 

```{r}
gam_train <- gam_train %>% 
  mutate(
    type = as.factor(type)
         ) 
```

Con esta funcion ya hecha podemos aplicarla a los distintos modelos para llegar al modelo con los parametros optimos. Vamos a generar entonces una lista de strings que correspondan a las formulas de los distintos modelos que querramos ajustar. De esta manera podemos iterar sobre esa lista de strings e ir comprobando el parametro optimo de k para cada modelo. 

```{r}
modelos_candidatos <- list(
  'type',
  'runtime',
  'release_year',
  'genres',
  'production_countries',
  'age_certificaction'
)

map(modelos_candidatos,
    ~k_optimo_finder(.x, grilla_k)
    )
modelos_candidatos_optimizados <- ''
```

Para cada modelo con los parametros optimos calculamos el RMSE segun 10-fold cross validation y nos quedamos con el que tenga el mejor desempeño. Generamos para esto una funcion.

```{r}
rmse_fun <- function(datos, gam_formula){
  #Esta funcion toma dos argumentos
  # -los datos para usar en la validacion cruzada
  # -una string que representa la formula del gam
  
  objeto_rsplit <- vfold_cv(datos, v = 10) 
  objeto_rsplit$splits %>%
  map(#En el mismo llamado vamos a predecir ajustando el modelo en el primer parametro
    ~ predict(
      gam(as.formula(gam_formula), family = betar(link='logit'), data = analysis(.x)), #Armo el modelo
      assessment(.x) #Saco las predicciones para el set de testeo
      ) - assessment(.x)$imdb_score #Le resto el valor real para calcular el error 
  ) %>%
  map(
    ~ sqrt(
      sum(.x^2, na.rm = T)/length(.x)
           )
      ) %>%
    unlist() #Convertimos el resultado en un vector
}
```

Ahora para aplicar la funcion tenemos que crear una lista de strings que correspondan a las formulas de los modelos con los parametros optimos ya seteados. Iteramos por esta lista y calculamos para cada caso el RMSE. 

Vamos a correr 2 variantes. La primera variante implica dejar los argumentos por default de la funcion `s()`. La segunda variante implica utilizar el valor de k optimo segun fue elegido anteriormente. 

```{r}
map(
  modelos_candidatos_optimizados,
  ~rmse_fun(titles_train_trans, .x)
)
```




```{r}
gam(imdb_score ~ s(release_year, bs = 'cr') + type,
    data = gam_train %>% mutate(age_certification = as.factor(age_certification))) %>%
  predict(gam_test) %>%
  tibble(predicciones = .) %>% 
    mutate(
      true_value = gam_test %>% pull(imdb_score),
      error_cuadratico = (predicciones - true_value)^2
           ) %>%
    summarise(
      rmse = sqrt(mean(error_cuadratico, na.rm = T))
    )
```


```{r}
gam(imdb_score ~ s(release_year, bs = 'cr', by = type) + type,
    data = gam_train %>% mutate(age_certification = as.factor(age_certification))) %>%
  predict(gam_test) %>%
  tibble(predicciones = .) %>% 
    mutate(
      true_value = gam_test %>% pull(imdb_score),
      error_cuadratico = (predicciones - true_value)^2
           ) %>%
    summarise(
      rmse = sqrt(mean(error_cuadratico, na.rm = T))
    )
```

