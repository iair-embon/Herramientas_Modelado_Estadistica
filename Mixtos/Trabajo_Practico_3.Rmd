---
title: "Trabajo Practico 3"
author: "Alejandro Ramos Usaj y Iair Embon"
date: '2022-07-07'
output: html_document
---
Cargo librerias que vamos a utilizar
```{r}
library(tidyverse)
library(mgcv)
```

Cargo los datos
```{r}
root <- rprojroot::is_rstudio_project
basename(getwd())

titles_train <- read.csv(root$find_file("Mixtos/titles_train.csv"))
credits_train <- read.csv(root$find_file("Mixtos/credits_train.csv"))
```

# 1

Primero tengo que normalizar la base de datos de entrenamiento que tiene muchos generos metidos en una sola columna. Queremos que cada genero sea una sola columna y que tenga un valor de 1 indicando si esa fila pertenece a ese genero y 0 de otra manera. 

Para esto en primer lugar eliminamos de las filas de la columna genero todos los caracteres que no corresponden con letras o comas. De esta manera deberiamos quedarnos con una estructura que sea "genero1, genero2, ..., generoN". De ahora en mas comprobamos el procedimiento extrayendo 10 datos aleatoriamente del dataframe resultante posterior a la manipulacion.
```{r}
titles_train %>% 
  mutate(genres = str_replace_all(genres,"[^A-Za-z,]","")) %>%
  slice_sample(n = 10) %>%
  pull(genres)
```

A continuacion usamos la funcion de `separate_rows` para separar los generos por coma de manera que cada uno sea una fila nueva. 
```{r}
titles_train %>% 
  mutate(genres = str_replace_all(genres,"[^A-Za-z,]","")) %>% 
  separate_rows(genres, sep = ',') %>% 
  slice_sample(n = 10) %>%
  select(title, genres)
```

Proximamente generamos una columna dummy nueva con todos valores de 1 para usar como valores cuando pasemos el dataframe a formato wide. Asi mismo filtramos aquellas filas que quedaron sin ningun genero (sin caracteres) como consecuencia de la funcion `separate_rows`.
```{r}
titles_train %>% 
  mutate(genres = str_replace_all(genres,"[^A-Za-z,]","")) %>% 
  separate_rows(genres, sep = ',') %>% 
  mutate(dummy = 1) %>% filter(genres != '') %>% 
  slice_sample(n = 10) %>%
  select(title, genres, dummy)
```

Por ultimo, vamos a usar la funcion `pivor_wider` para convertir el dataframe de formato long (como esta ahora, con filas repetidas para distintos titulos) a formato wide, donde cada genero corresponda a una columna con valores dados por la columna dummy. 
```{r}
titles_train %>% 
  mutate(genres = str_replace_all(genres,"[^A-Za-z,]","")) %>% 
  separate_rows(genres, sep = ',') %>% 
  mutate(dummy = 1) %>% filter(genres != '') %>% 
  pivot_wider(names_from = genres, values_from = dummy) %>% 
  slice_sample(n = 10) %>%
  select(title, comedy:sport)
```

A continuacion, reemplazamos aquellos valores que quedaron como `NA` con un 0 indicando que ese genero no pertenece a ese titulo y escribimos todo el procedimiento anterior en un solo bloque. 
```{r}
titles_train_trans <- titles_train %>% 
  mutate(genres = str_replace_all(genres,"[^A-Za-z,]","")) %>% 
  separate_rows(genres, sep = ',') %>% 
  mutate(dummy = 1) %>% filter(genres != '') %>% 
  pivot_wider(names_from = genres, values_from = dummy) %>% 
  mutate(across(comedy:sport, ~ replace_na(.x, 0))) 
```

Por ultimo, podria ser interesante tener una columna que cuente cuantos generos tiene un determinado titulo y para esto vamos a agregar una columna nueva sumando los 1 para todas las columnas correspondientes a los distintos generos. 
```{r}
titles_train_trans <- titles_train_trans %>% mutate(cant_genres = rowSums(across(comedy:sport)))
```

Ahora queremos normalizar la columna correspondiente a los paises encargados de la produccion. Sin embargo, hay demasiados paises involucrados, muchos mas que en el caso de los generos, lo que nos dejaria con demasiadas columnas con muchos valores en 0. 
```{r}
titles_train_trans <- titles_train_trans %>% 
  mutate(production_countries = str_replace_all(production_countries,"[^A-Za-z,]","")) %>% 
  mutate(
    production_countries = strsplit(production_countries, ','),
    production_countries = lapply(production_countries, sort),
    production_countries = as.character(production_countries)
  ) %>%
  unnest(cols = production_countries) %>%
  mutate(production_countries = str_replace_all(production_countries,"[^A-Z,]",""))
```


## a)

Exploramos el genero en base al puntaje imdb
```{r}
titles_train %>% 
  mutate(genres = str_replace_all(genres,"[^A-Za-z,]","")) %>% 
  separate_rows(genres, sep = ',') %>% filter(genres != '') %>%
  ggplot(
    aes(x = genres, y = imdb_score)
  ) +
    geom_boxplot()+
  theme(axis.text.x = element_text(angle = 45, hjust=1))
```

## b)

Exploramos el puntaje a lo largo de los años
```{r}
titles_train %>% 
  mutate(genres = str_replace_all(genres,"[^A-Za-z,]","")) %>% 
  separate_rows(genres, sep = ',') %>% filter(genres != '', !is.na(imdb_score)) %>%
  ggplot(aes(x= release_year, y=imdb_score)) +
    geom_line() +
    geom_point()
   
```

Ahora exploramos el puntaje a lo largo de los años teniendo en cuenta el genero
```{r}
titles_train %>% 
  mutate(genres = str_replace_all(genres,"[^A-Za-z,]","")) %>% 
  separate_rows(genres, sep = ',') %>% filter(genres != '', !is.na(imdb_score)) %>%
  ggplot(aes(x=release_year, y=imdb_score, color = genres)) +
    geom_line() +
    facet_wrap("genres") +
   theme(axis.text.x = element_text(angle = 45, hjust=1))
```

## c)

Para explorar lo pedido, se combinan el dataframe que contiene la informacion de las personas que ocupan rol de director o actor, y el dataframe que contiene la informacion del puntaje imdb, utilizando la columna llave "id". Luego se imprimen los 10 actores o directores que mejores y peores puntajes tienen.
```{r}
# Primero combino credits_train con titles_train utilizando la columna "id"
titulos_creditos_combinados<- inner_join(titles_train, credits_train, by = "id")

# Veo los 10 actores o directores que mejores puntajes tienen
titulos_creditos_combinados %>%
  group_by(titulos_creditos_combinados$person_id) %>%
  summarise(mean = mean(imdb_score)) %>%
  top_n(10)

# Veo los 10 actores o directores que peores puntajes tienen
titulos_creditos_combinados %>%
  group_by(titulos_creditos_combinados$person_id) %>%
  summarise(mean = mean(imdb_score)) %>%
  top_n(-10)
```

## d)

Se tomara la columna imdb_votes como una medida de popularidad, suponiendo que la cantidad de votos estaria asociado con la cantidad de personas que ven un film determinado.
Pareceria ser que la cantidad de votos y el puntaje esta asociado de manera postiva.
```{r}
titles_train %>%
  ggplot(aes(imdb_votes, imdb_score)) +
    geom_point()

# ahora me fijo en los que tienen menos de 250000 votos
titles_train %>%
  ggplot(aes(imdb_votes, imdb_score)) +
    geom_point() +
    xlim(0,250000)
```

## e)

```{r}
library(tidytext)
```

Primero armo un nuevo dataframe con las palabras tokenizadas de los titulos de las peliculas.
```{r}
data("stop_words")

token_titles <- titles_train %>%
  #Convierto los titulos de las peliculas en string porque esta como factor
  mutate(title = as.character(title)) %>%
  #Saco unicamente las columnas que me interesan que son el id, el titulo y el puntaje.
  select(id, title, imdb_score) %>%
  #Tokenizo la columna del titulo
  unnest_tokens(palabras, title) %>% 
  #Agrupo por id
  group_by(id) %>%
  #Calculo la posicion de cada palabra en el titulo aprovechando que agrupe por id
  mutate(word_number = row_number()) %>%
  #Elimino las stopwords
  filter(!palabras %in% stop_words$word) %>%
  ungroup()
```

Calculo ahora la mediana de puntaje para cada palabra y me quedo con aquellas palabras que aparezcan mas de una determinada cantidad de veces. Para definir esto ultimo primero miramos un histograma en escala logaritmica del eje y para ver mejor el patron.

```{r}
token_titles %>% count(palabras) %>% 
  ggplot(aes(x = n)) + 
  geom_histogram() +
  scale_y_log10()
```

Vamos a suponer que una palabra tuvo que haber aparecido por lo menos 15 veces para ser contabilizada con lo cual filtramos las palabras con menos de 15 apariciones. Luego de lo cual podemos filtrar los titulos que no tienen puntaje de imdb, luego agrupamos por palabra y calculamos la mediana para graficar.

```{r}
mediana_titles <- token_titles %>%
  filter(
    palabras %in% (token_titles %>% count(palabras) %>% filter(n >= 15) %>% pull(palabras))
  ) %>%
  filter(!is.na(imdb_score)) %>%
  group_by(palabras) %>%
  summarise(mediana = median(imdb_score))

mediana_titles %>%
  ggplot(aes(x = reorder(palabras, -mediana), y = mediana)) +
  geom_segment(aes(x = reorder(palabras, -mediana), xend = reorder(palabras, -mediana), y = 5, yend = mediana)) +
  geom_point() +
  ylab('Median score') + xlab('Words') +
  coord_flip()
```

Quedaron algunas stopwords de otros idiomas como el español que no fueron captadas por el dataframe de stopwords que utilizamos. Para eliminarlas habria que utilizar alguna referencia de stopwords con mayor representacion multilinguistica. 

## Exploramos otras variables que nos interesan

Exploro type y el puntaje imdb
```{r}
table(titles_train$type)

titles_train %>% 
  filter(!is.na(imdb_score)) %>%
  ggplot(aes(x=type, y=imdb_score)) + 
    geom_boxplot()
```

Exploro type y el puntaje imdb, segun el genero
```{r}
titles_train %>% 
  mutate(genres = str_replace_all(genres,"[^A-Za-z,]","")) %>% 
  separate_rows(genres, sep = ',') %>% 
  filter(genres != '', !is.na(imdb_score)) %>%
  ggplot(aes(x=type, y=imdb_score, fill= genres)) + 
    geom_boxplot()
```

Exploro el puntaje imdb en relacion a los paises
```{r}
titles_train_trans %>%
  mutate(production_countries = str_replace_all(production_countries,"[^A-Za-z,]","")) %>% 
  separate_rows(production_countries, sep = ',') %>% 
  filter(production_countries != '', !is.na(imdb_score)) %>%
  mutate(production_countries = fct_lump_n(production_countries, 10, other_level = "Otros")) %>%
  ggplot(aes(x=production_countries, y=imdb_score)) + 
    geom_boxplot()
```

Exploro el puntaje imdb por pais en el tiempo
```{r}
titles_train_trans %>%
  mutate(production_countries = str_replace_all(production_countries,"[^A-Za-z,]","")) %>% 
  separate_rows(production_countries, sep = ',') %>% 
  filter(production_countries != '', !is.na(imdb_score)) %>%
  mutate(production_countries = fct_lump_n(production_countries, 10, other_level = "Otros")) %>%
  ggplot(aes(x=release_year, y=imdb_score, color = production_countries)) +
    geom_line() +
    facet_wrap("production_countries") +
   theme(axis.text.x = element_text(angle = 45, hjust=1))
   
```

Exploro la variable runtime en relacion al puntaje imdb
```{r}
library(ggExtra)

p <- titles_train_trans %>%
  filter( !is.na(imdb_score)) %>%
  ggplot(aes(x=runtime, y=imdb_score)) +
      geom_point() +
      theme(legend.position="none")

ggMarginal(p, margins = 'both', color="purple", size=4)
```

Exploro la variable seasons en relacion al puntaje imdb
```{r}
library(ggExtra)

p <- titles_train_trans %>%
  filter(!is.na(imdb_score), !is.na(seasons)) %>%
  ggplot(aes(x=seasons, y=imdb_score)) +
      geom_point() +
      theme(legend.position="none")

ggMarginal(p, margins = 'both', color="purple", size=4)
```

Exploro el puntaje imdb en relacion al age_certification
```{r}
titles_train_trans %>%
  filter(!is.na(imdb_score),!is.na(age_certification)) %>%
  ggplot(aes(x=age_certification, y=imdb_score)) + 
    geom_boxplot()
```

# 2

Agarro el df que tenia los paises en una coluna, y agrupo todos los que son menores de 5 en la categoria "otros"
```{r}
titles_train_trans_OtrosPaises <- titles_train_trans %>%
  filter(production_countries != '',!is.na(imdb_score)) %>%
  mutate(production_countries = fct_lump_min(production_countries, 5, other_level = "Otros"))
```

## a)

Corro un modelo lineal para predecir el puntaje de imdb con production_countries. El modelo es de efectos fijos.
```{r}
m_EfectosFijos <- lm(imdb_score ~ production_countries, data = titles_train_trans_OtrosPaises)

summary(m_EfectosFijos)
```

## b)

Corro un modelo lineal multiple mixto para predecir el puntaje de imdb con production_countries. El modelo tiene la intercept como efecto fijo, mas un efecto aleatorio por production_countries.
```{r}
library(lme4)
m_InterceptAleatoria <- lmer(imdb_score ~ (1|production_countries), data = titles_train_trans_OtrosPaises)

summary(m_InterceptAleatoria)
ranef(m_InterceptAleatoria)
```

## c)

Uilizando parte del script que uso el profesor en clase, grafico las intercepts fijas y aleatorias 
```{r}
library(ggrepel)
# calculo en numero de casos de production_countries
n_casos_production_countries = titles_train_trans_OtrosPaises %>% 
  group_by(production_countries) %>% 
  summarise(num_cases = n()) %>% 
  pull(num_cases)

# Obtengo intercepts aleatorios con fit_3
lmm_intercepts = ranef(m_InterceptAleatoria)[['production_countries']][,1] +fixef(m_InterceptAleatoria)[['(Intercept)']]

# Obtengo intercepts fijos con fit_1
fixed_intercepts = as.array(m_EfectosFijos$coefficients) 
# le sumo la intercept a cada beta del modelo fijo para que esten mas cercanos a las intercept del modelo mixto y los pueda comparar
fixed_intercepts = c(fixed_intercepts[1],
                     as.array(m_EfectosFijos$coefficients)[2:length(fixed_intercepts)]+fixed_intercepts[1])

# Grafico efectos fijos vs efectos aleatorios, incluyendo el tamano de muestra como size
tibble(lmm = lmm_intercepts, 
       fixed = fixed_intercepts, 
       num_cases = n_casos_production_countries,
       pr_count = sort(unique(titles_train_trans_OtrosPaises$production_countries))) %>%
  mutate(rn = row_number()) %>% 
  pivot_longer(c(fixed, lmm)) %>% 
  ggplot(aes(x = rn, y = value, label= pr_count, color = name)) +
  geom_point(aes(size = num_cases), alpha = 0.5) +
  geom_text_repel(aes(label = pr_count)) +
  theme_bw() +
  theme(legend.position = 'bottom')

## En el grafico se puede ver que los paises que tienen una mayor cantidad de casos los afecta menos si se utiliza un modelo de efectos aleatorios o un modelo de efectos fijos. Cuando los paises tienen pocos casos, desde el modelo de efectos aleatorios, se acercan mas hacia la media, en comparacion con lo que hace con esos mismos paises el modelo de efectos fijos. 
```

# 3

## a)

Agregamos al modelo del item 2b (el de la intercept aleatoria por paises) el predictor release_year, y luego decidimos si valio la pena utilizando anova 
```{r}
# corro el modelo
m2_InterceptAleatoria_release_year <- lmer(imdb_score ~ release_year + (1|production_countries), data = titles_train_trans_OtrosPaises)

# veo los resultados
summary(m2_InterceptAleatoria_release_year)
ranef(m2_InterceptAleatoria_release_year)

# decido si vale la pena sumar al modelo la variable release_year usando anova
anova(m_InterceptAleatoria,
      m2_InterceptAleatoria_release_year)

# basado en el resultado del anova, pareceria que si valdria la pena agregar release_year al modelo del item 2b
```

## b)

Separo en datos de entrenamiento y de testeo, luego comparo m_InterceptAleatoria y m2_InterceptAleatoria_release_year, y por ultimo selecciono el que tenga un menor error cuadratico medio en los datos del testeo
```{r}
# divido en datos de entrenamiento y de testeo
entrenamiento <- titles_train_trans_OtrosPaises %>%
  slice_sample(prop = 0.8)

testeo <- titles_train_trans_OtrosPaises %>%
  slice(-pull(entrenamiento,X))

# entreno los modelos en la data de entrenamiento

m_InterceptAleatoria_entrenamiento <- lmer(imdb_score ~ (1|production_countries), data = entrenamiento)

m2_InterceptAleatoria_release_year_entrenamiento <- lmer(imdb_score ~ release_year + (1|production_countries), data = entrenamiento)

# predigo usando la data de testeo con el primer modelo
predicciones_m <- predict(m_InterceptAleatoria_entrenamiento, testeo)

# predigo usando la data de testeo con el segundo modelo
predicciones_m2 <- predict(m2_InterceptAleatoria_release_year_entrenamiento, testeo)

# creo una funcion que calcule el error cuadratico medio
error_cuadratico_medio <- function(y_predic, y){
  error <- mean((y - y_predic)**2)
  return(error)
}

error_cuadratico_medio_m <- error_cuadratico_medio(predicciones_m, testeo$imdb_score)
error_cuadratico_medio_m2 <- error_cuadratico_medio(predicciones_m2, testeo$imdb_score)
```

## c) 

Mientras que el anova permite observar una significancia estadistica al agregar el predictor release_year con respecto al modelo que no tiene este predictor, el error cuadratico medio al comparar ambos predictores no pareciera ser abismal. Si comparamos estos dos procedimientos, el anova mide como impacta el hecho de agregar un predictor (release_year) en los residuales. En este caso (el que observamos nosotros), impacto de manera significativa. Sin embargo, el error cuadratico medio, que evalua que tan bien predice el modelo, pareciera no variar en gran medida al agregar el predictor "release_year". El error cuadratico medio es una metrica predictiva. Ademas, el anova supone una cierta distrubicion, con ciertos grados de libertad, es decir, es una metrica parametrica. A diferencia del error cuadratico medio, que es no parametrico.

-----

# 4)

## a)

```{r}
#Definimos los posibles valores de k para comparar
k_values <- c(1,2,3,5,10,20,50)

#Ajusto el modelo con cada valor del vector de posibles valores de k y voy guardando en una lista
gam_fits <- lapply(
  k_values,
  function(x) gam(imdb_score ~ s(release_year, bs = 'cr', k = x), data = titles_train_trans)
)

#Armo una lista con las predicciones
lista_predicciones <- lapply(gam_fits, 
                function(x) predict(x, titles_train_trans)
                )

#Combino la lista en un solo dataframe
df_predicciones <- tibble(prediccion = unlist(lista_predicciones)) %>% 
  mutate(
    k = rep(k_values, each = nrow(titles_train_trans)),
    covariada = rep(titles_train_trans$release_year, length(k_values))
    )

#Grafico los datos de entrenamiento y las predicciones para cada valor de k
df_predicciones %>%
  ggplot(
    aes(x = covariada, y = prediccion, color = as.factor(k))
         ) +
  geom_line() +
  xlab('Release Year') + ylab('Prediccion') +
  scale_color_discrete('Valor de k')
```
Cuando armamos el modelo, los niveles de k mas bajos no lograron ajustarse correctamente por lo que la funcion elevo k al nivel minimo, y por eso no se ven diferencias con las curvas de los valores mas bajos. 

## b)

Generamos la particion

```{r}
#Planto la semilla
set.seed(1234)

#Separo en entrenamiento y testeo
gam_train <- titles_train_trans %>%
  slice_sample(prop = 0.8)
gam_test <- titles_train_trans %>%
  filter(
    !id %in% gam_train$id
  )
```

Calculo el RMSE para cada caso

```{r}
rmse_gam <- lapply(
  k_values,
  function(x) gam(imdb_score ~ s(release_year, bs = 'cr', k = x), data = gam_train) %>%
    predict(gam_test) %>%
    tibble(predicciones = .) %>% 
    mutate(
      true_value = gam_test %>% pull(imdb_score),
      error_cuadratico = (predicciones - true_value)^2
           ) %>%
    summarise(
      rmse = sqrt(mean(error_cuadratico, na.rm = T))
    )
) %>% 
  bind_rows() %>%
  mutate(k = k_values)
```

Ahora simplemente visualizamos

```{r}
rmse_gam %>%
  ggplot(aes(x = k, y = rmse)) +
  geom_point() + geom_line()
```

Igual que antes los valores k mas bajos (menores a 3) terminan llevandose a un mismo valor minimo de k por la funcion. En consecuencia, no hay diferencias en esos RMSE. Despues de visualizar calculamos el valor que minimiza.

```{r}
rmse_gam$k[which.min(rmse_gam$rmse)]
```

# 5)

```{r}
library(rsample)
set.seed(4567)
```

Para encontrar el k optimo de cada modelo vamos a utilizar un approach similar al del ejercicio 4 utilizando la misma division de datos.
En este caso sin embargo ponemos todo dentro de una funcion para correrlo con los distintos modelos seleccionados. Necesitamos entonces una funcion que ajuste el modelo en los datos de entrenamiento variando el valor de k y compare las predicciones con el dataset de testeo para hallar el k optimo. Cada funcion puede tener distintos niveles del valor k eso significa que tenemos que encontrar la combinacion de valores de k que llega al resultado optimo. Sin embargo la complejidad con la que crece el espacio de parametros posibles a explorar es la longitud de la grilla de posibles valores de k elevado a la cantidad de covariadas que tenga el modelo. Sin embargo la mayoria de las variables que nos interesan no son continuas por lo que unicamente tenemos que estimar este parametro para 2 variables como maximo que son `release_year` y `runtime`. 

Para esto vamos a armar una lista con todas las combinaciones posibles de 25 valores k entre 1 y 50. Dado que algunos modelos tienen que explorar unicamente una grilla de valores k unidimensional y otros modelos tienen que explorar una grilla multidimensional vamos a implementar en la funcion la capacidad de lidiar con cualquier caso pasando siempre el mismo objeto. De lo contrario habria que crear una correspondia entre espacio de parametros y modelo para que la iteracion se haga segun esa correspondencia. Tomando eso en cuenta utilizamos unicamente la version mas grande que es la lista con las combinaciones de dos posibles valores de k. 


```{r}
grilla_k <- round(seq(1,50, length.out = 25)) #Una grilla de valores k de 1 hasta 50 con longitud total 25


lista_k <- tidyr::expand_grid(release_k = grilla_k, runtime_k = grilla_k) %>% as.list() #lista con los valores posibles de k para dos variables


k_optimo_finder <- function(modelo_gam, potenciales_k){
  #modelo_gam = string que contenga la formula para usar en la funcion gam con argumentos de k dentro de la funcion s iguales a .x y .y
  #potenciales_k = lista con las combinaciones de posibles valores k o los unicos valores de k 

  #Primero se itera por todos los potenciales valores de k
  pmap(potenciales_k,
      ~ gam( #Genero una cantidad de modelos igual a la cantidad de k candidatos
        as.formula(modelo_gam), 
        data = gam_train) 
  ) %>%
    map(
      ~ predict(.x, gam_test) - gam_test$imdb_score #Calculo la diferencia con la prediccion para cada potencial k sobre el conjunto de testeo
    ) %>%
    map( #Calculo el RMSE para ese k
      ~ sqrt(
      mean(.x^2, na.rm = T)
           )
    ) %>%
    unlist() %>% #Convierto la lista en un vector
    which.min() #Calculo el indice del valor k optimo
}
```

Vamos a hacer una nueva separacion de los datasets para trabajar. En este caso convertimos paises de produccion en una variable factorial donde colapsamos aquellos casos con pocas observaciones. como factor las variables que vayamos a usar en el GAM porque sino el modelo tira un error. 

```{r}
gam_cv <- titles_train_trans %>%
  mutate(
    type = as.factor(type),
    production_countries = as.factor(production_countries),
    age_certification = as.factor(age_certification),
    production_countries = forcats::fct_lump(production_countries, prop = .05)
         ) %>%
  group_by(production_countries) 
gam_train <- gam_cv %>%
  slice_sample(prop = 0.8)
gam_test <- gam_cv %>%
  filter(
    !id %in% gam_train$id
  )
```

Con esta funcion ya hecha, podemos aplicarla a los distintos modelos para llegar al modelo con los parametros optimos. Vamos a generar entonces una lista de strings que correspondan a las formulas de los distintos modelos que querramos ajustar. De esta manera, podemos iterar sobre esa lista de strings e ir comprobando el parametro optimo de k para cada modelo. 

```{r, warning=FALSE}
modelos_candidatos <- list(
  "imdb_score ~ s(release_year, bs = 'cr', k = .x)",
  "imdb_score ~ s(runtime, bs = 'cr', k = .x)",
  "imdb_score ~ s(release_year, bs = 'cr', k = .x) + type",
  "imdb_score ~ s(release_year, bs = 'cr', by = type, k = .x) + type",
  "imdb_score ~ s(runtime, bs = 'cr', k = .x) + type",
  "imdb_score ~ s(runtime, bs = 'cr', by = type, k = .x) + type",
  "imdb_score ~ s(release_year, bs = 'cr', k = .x) + s(runtime, bs = 'cr', k = .y)",
  "imdb_score ~ s(release_year, bs = 'cr', k = .x) + s(runtime, bs = 'cr', k = .y) + type",
  "imdb_score ~ s(release_year, bs = 'cr', by = type, k = .x) + s(runtime, bs = 'cr', by = type , k = .y) + type",
  "imdb_score ~ s(imdb_votes, bs = 'cr', k = .x)",
  "imdb_score ~ s(imdb_votes, bs = 'cr', k = .x) + type",
  "imdb_score ~ s(imdb_votes, bs = 'cr', by = type, k = .x) + type",
  "imdb_score ~ s(imdb_votes, bs = 'cr', k = .x) + s(runtime, bs = 'cr', k = .y)",
  "imdb_score ~ s(imdb_votes, bs = 'cr', k = .x) + s(runtime, bs = 'cr', k = .y) + type",
  "imdb_score ~ s(imdb_votes, bs = 'cr', by = type, k = .x) + s(runtime, bs = 'cr', by = type , k = .y) + type",
  "imdb_score ~ s(release_year, bs = 'cr', k = .x) + s(imdb_votes, bs = 'cr', k = .y)",
  "imdb_score ~ s(release_year, bs = 'cr', k = .x) + s(imdb_votes, bs = 'cr', k = .y) + type",
  "imdb_score ~ s(release_year, bs = 'cr', by = type, k = .x) + s(imdb_votes, bs = 'cr', by = type , k = .y) + type",
  "imdb_score ~ s(release_year, bs = 'cr', by = type, k = .x) + s(imdb_votes, bs = 'cr', by = type , k = .y) + type + production_countries + age_certification",
    "imdb_score ~ s(release_year, bs = 'cr', k = .x)",
    "imdb_score ~ s(release_year, bs = 'cr', k = .x) + production_countries",
  "imdb_score ~ s(release_year, bs = 'cr', by = type, k = .x) + s(imdb_votes, bs = 'cr', by = type , k = .y) + type + production_countries"
  )

resultado_k_optimo <-  map(modelos_candidatos,
    ~k_optimo_finder(.x, lista_k)
    )
```

Como resultado hay una lista donde cada elemento refiere al indice del objeto que le fue pasado a la funcion, en este caso `lista_k`, donde se encuentran el o los valores k optimos. 

Para asignar de manera automatica el valor k adecuado para cada modelo asi como determinar si el valor corresponde a un solo k o a una combinacion de k tenemos que chequear las strings. Para eso iteramos por todos los modelos y para cada caso nos vamos a fijar si tiene ".y". En caso positivo es que hay un dos k y tenemos que tomar segun el indice del primer y segundo elemento de la lista de posibles k que se le paso a la funcion `k_optimo_finder`, caso contrario tiene un solo k y se toma segun el indice del primer elemento de la lista. 


```{r}
#Creo una lista las strings de las formulas para los modelos con los valores de k reemplazados por aquellos optimos 
modelos_optimizados <- list()

#Itero por la lista de los modelos candidatos
for(i in seq_along(modelos_candidatos)){
  
  #Alberga un vector atomico con el o los valores de k
  k_optimo_por_modelo <- ifelse(
    str_detect( #Chequeo si en la string de la formula esta la string '.y' 
      modelos_candidatos[[i]], #Selecciono la string de la formula correspondiente con el modelo de la interaccion actual. 
      '\\.y' #Patron para tratar de encontrar ".y" escapando el punto
    ) == TRUE, #Si lo encuentra significa que ese modelo utiliza dos valores k, sino tiene uno solo
    paste(#Selecciono el iesimo valor del primer y segggundo elemento de la lista posibles k y los uno en una misma string
      lista_k[[1]][resultado_k_optimo[[i]]], lista_k[[2]][resultado_k_optimo[[i]]], sep = ','
      ),
    c(#En caso false selecciono el iesimo valor pero solo del primer elemento de la lista de posibles k
      lista_k[[1]][resultado_k_optimo[[i]]]
    )
  )
  
  #Si el modelo tenia dos valores quedo como una sola string separada por ',' asi que lo convierto en un vector separando por ','
  k_optimo_por_modelo <- str_split(k_optimo_por_modelo,',')[[1]]
  #Si el modelo tenia un solo valor entonces no hace nada mas que convertirlo en un caracter
  #En ambos casos termino con un vector de caracteres
  
  #Agrego la string de la formula reemplazando los valores en la lista correspondiente que cree al principio
  modelos_optimizados[[i]] <- ifelse(
    length(k_optimo_por_modelo) > 1, #Chequeo la longitud del vector para ver si hay mas de un valor de k en consideracion
    str_replace_all(modelos_candidatos[[i]], #Si hay mas de un k reemplazo en dos lugares
                c('\\.x' = k_optimo_por_modelo[1], '\\.y' = k_optimo_por_modelo[2]) #Los '.x por el primer k y los '.y' po rel segundo
                ),
    str_replace(modelos_candidatos[[i]], #Si hay un solo k reemplazo unicamente en un solo lugar
                '\\.x', #Reemplazo el '.x' que tendria que tener una sola aparicion
                k_optimo_por_modelo) #Se reemplaza por el vector donde esta alojado el k optimo sin seleccionar porque hay un solo valor
  )
}
```



Para cada modelo con los parametros optimos calculamos el RMSE segun 10-fold cross validation y nos quedamos con el que tenga el mejor desempeño. Generamos para esto una funcion.

```{r}
rmse_fun <- function(datos, gam_formula){
  #Esta funcion toma dos argumentos
  # -los datos para usar en la validacion cruzada
  # -una string que representa la formula del gam
  
  objeto_rsplit <- vfold_cv(datos, v = 10, strata = type) 
  objeto_rsplit$splits %>%
  map(#En el mismo llamado vamos a predecir ajustando el modelo en el primer parametro
    ~ predict(
      gam(as.formula(gam_formula), data = analysis(.x)), #Armo el modelo
      assessment(.x) #Saco las predicciones para el set de testeo
      ) - assessment(.x)$imdb_score #Le resto el valor real para calcular el error 
  ) %>%
  map(
    ~ sqrt(
      sum(.x^2, na.rm = T)/length(.x)
           )
      ) %>%
    unlist() #Convertimos el resultado en un vector
}
```

Ahora para aplicar la funcion tenemos que crear una lista de strings que correspondan a las formulas de los modelos con los parametros optimos ya seteados. Iteramos por esta lista y calculamos para cada caso el RMSE. 

Vamos a correr 2 variantes. La primera variante implica dejar los argumentos por default de la funcion `s()`. La segunda variante implica utilizar el valor de k optimo segun fue elegido anteriormente. Para la primera variante hay que re-escribir los modelos eliminando las menciones al valor k. Lo hacemos a continuacion.

```{r}
modelos_automatizados <- str_replace_all(modelos_optimizados, ', k = \\d+', '') %>% as.list()
```

Ahora corremos la primera variante.

```{r}
rmse_automatica_todos_modelos <- map(
  modelos_automatizados,
  ~rmse_fun(
    gam_cv %>% ungroup(), .x
  )
)
```

Corremos la segunda variante

```{r, warning=FALSE}
rmse_todos_modelos <- map(
  modelos_optimizados,
  ~rmse_fun(gam_cv %>% ungroup(), .x)
)
```

La idea ahora es armar un grafico donde comparemos por un lado la performance de los distintos modelos entre si y por otro lado entre la seleccion automatica del valor k que hace la funcion `s()` y la seleccion manual que implementamos nosotros. Para esto armamos un dataframe donde cada fila corresponda a un modelo, su respectivo RMSE y el fold en el que se obtuvo ese valor. Graficamos la media y el error estandard ordenando por el valor de la media de RMSE para tener una idea de que modelo elegir.

```{r}
comparacion_performance <- tibble(
  rmse = c(
    rmse_todos_modelos %>% unlist(), 
    rmse_automatica_todos_modelos %>% unlist()
    ),
  cv_fold = rep(1:10, length(rmse_todos_modelos)*2),
  modelo = rep(
    rep(modelos_optimizados %>% unlist(), each = 10),
    2
    ),
  tipo_k = rep(c('manual','automatico'), each = length(modelos_optimizados)*10)
)


comparacion_performance %>%
  mutate(class = fct_reorder(modelo, rmse, .fun='mean')) %>%
  ggplot(
  aes(x = reorder(modelo, rmse), y = rmse, color = tipo_k)
    ) +
  stat_summary(position = position_dodge(.9)) + 
  theme(
    axis.text.y = element_blank() 
  ) +
  coord_flip()
```

Elegimos el que minimizo el error y que el k fue elegido de manera manual (son muy parecidos igualmente, es decir, el automatico y el manual).
Tambien realizamos las predicciones, para luego guardarlas en un archivo .csv como pide la consigna 6

```{r}
# primero vamos a cargar el excel de testeo titles_test.csv, el de  credits_test.csv no ya que no lo usamos. Luego, preprocesamos los datos de testeo para que las columnas del modelo que mejor ajusta tengan un tratamiento similar al que le hicimos a los datos de entrenamiento. Estas son imbd_votes, type y runtime. Aunque solamnete modificamos type.

titles_test <- read.csv(root$find_file("Mixtos/titles_test.csv"))
credits_test <- read.csv(root$find_file("Mixtos/credits_test.csv"))

datos_testeo <- titles_test %>%
  mutate(
    type = as.factor(type))


predicciones_finales <- comparacion_performance %>%
  group_by(modelo, tipo_k) %>%
  summarise(media = mean(rmse), desvio = sd(rmse)) %>% arrange(media) %>%
  filter(tipo_k == "manual") %>%
  ungroup() %>%
  filter(row_number()==1) %>%
  pull(modelo) %>% 
  as.formula() %>%
  gam(data = gam_cv) %>%
  predict.gam(datos_testeo)

```


# 6)

Procedemos con el punto final.
Guardo en un archivo llamado predicciones.csv para luego enviar al profesor de la materia

```{r}
#write.table(predicciones,"Mixtos\\predicciones.csv",col.names = FALSE)
```

