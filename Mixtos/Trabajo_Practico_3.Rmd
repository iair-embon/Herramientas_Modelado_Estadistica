---
title: "Trabajo Practico 3"
author: "Alejandro Ramos Usaj y Iair Embon"
date: '2022-07-07'
output: html_document
---
Cargo librerias que vamos a utilizar
```{r}
library(tidyverse)
```

Cargo los datos
```{r}
root <- rprojroot::is_rstudio_project
basename(getwd())

titles_train <- read.csv(root$find_file("Mixtos/titles_train.csv"))
credits_train <- read.csv(root$find_file("Mixtos/credits_train.csv"))
```

# 1

Primero tengo que normalizar la base de datos de entrenamiento que tiene muchos generos metidos en una sola columna. Queremos que cada genero sea una sola columna y que tenga un valor de 1 indicando si esa fila pertenece a ese genero y 0 de otra manera. 

Para esto en primer lugar eliminamos de las filas con el genero de las peliculas a todos los caracteres que no corresponden con letras o comas. De esta manera deberiamos quedarnos con una estructura que sea "genero1, genero2, ..., generoN". De ahora en mas comprobamos el procedimiento extrayendo 10 datos aleatoriamente del dataframe resultante posterior a la manipulacion.
```{r}
titles_train %>% 
  mutate(genres = str_replace_all(genres,"[^A-Za-z,]","")) %>%
  slice_sample(n = 10) %>%
  pull(genres)
```

A continuacion usamos la funcion de `separate_rows` para separar los generos por coma de manera que cada uno sea una fila nueva. 
```{r}
titles_train %>% 
  mutate(genres = str_replace_all(genres,"[^A-Za-z,]","")) %>% 
  separate_rows(genres, sep = ',') %>% 
  slice_sample(n = 10) %>%
  select(title, genres)
```

Proximamente generamos una columna dummy nueva con todos valores de 1 para usar como valores cuando pasemos el dataframe a formato wide. Asimismo filtramos aquellas filas que quedaron sin ningun genero (sin caracteres) como consecuencia de la funcion `separate_rows`.
```{r}
titles_train %>% 
  mutate(genres = str_replace_all(genres,"[^A-Za-z,]","")) %>% 
  separate_rows(genres, sep = ',') %>% 
  mutate(dummy = 1) %>% filter(genres != '') %>% 
  slice_sample(n = 10) %>%
  select(title, genres, dummy)
```

Por ultimo vamos a usar la funcion `pivor_wider` para convertir el dataframe de formato long (como esta ahora, con filas repetidas para distintos titulos) a formato wide donde cada genero corresponda a una columna con valores dados por la columna dummy. 
```{r}
titles_train %>% 
  mutate(genres = str_replace_all(genres,"[^A-Za-z,]","")) %>% 
  separate_rows(genres, sep = ',') %>% 
  mutate(dummy = 1) %>% filter(genres != '') %>% 
  pivot_wider(names_from = genres, values_from = dummy) %>% 
  slice_sample(n = 10) %>%
  select(title, comedy:sport)
```

Finalmente reemplazamos aquellos valores que quedaron como `NA` con un 0 indicando que ese genero no pertenece a ese titulo y escribimos todo el procedimiento anterior en un solo bloque. 
```{r}
titles_train_trans <- titles_train %>% 
  mutate(genres = str_replace_all(genres,"[^A-Za-z,]","")) %>% 
  separate_rows(genres, sep = ',') %>% 
  mutate(dummy = 1) %>% filter(genres != '') %>% 
  pivot_wider(names_from = genres, values_from = dummy) %>% 
  mutate(across(comedy:sport, ~ replace_na(.x, 0))) 
```

Por ultimo podria ser interesante tener una columna que cuente cuantos generos tiene un determinado titulo y para esto vamos a agregar una columna nueva sumando los 1 para todas las columnas correspondientes a los distintos generos. 
```{r}
titles_train_trans <- titles_train_trans %>% mutate(cant_genres = rowSums(across(comedy:sport)))
```

Solo falta normalizar la columna correspondiente a los paises encargados de la produccion. Sin embargo hay demasiados paises involucrados, muchos mas que en el caso de los generos lo que nos dejaria con demasiadas columnas con muchos valores en 0. 
```{r}
titles_train_trans <-  titles_train_trans %>% 
  mutate(production_countries = str_replace_all(production_countries,"[^A-Za-z,]","")) %>% 
  separate_rows(production_countries, sep = ',') %>% 
  distinct(id, .keep_all = T)
```

<<<<<<< HEAD
Podemos comprobar tambien la frecuencia de cada pais para ver que tan concentrados estan los datos alrededor de determinados paises. 
=======
Si quisieramos ir por la otra via podemos comprobar tambien la frecuencia de cada pais para ver que tan concentrados estan los datos alrededor de determinados paises. 

>>>>>>> 2b4f452e03a2f57fd95c8871a1a28b1e3d056fdb
```{r}
titles_train %>% 
  mutate(production_countries = str_replace_all(production_countries,"[^A-Za-z,]","")) %>% 
  separate_rows(production_countries, sep = ',') %>% 
  filter(production_countries != '') %>%
  count(production_countries) %>% 
  ggplot(aes(x = production_countries, y = n)) +
  geom_col() + theme(axis.text.x = element_blank())
```

Vemos que hay unos pocos paises que concentran la mayoria de los datos. Generamos entonces 10 factores y el resto quedan como "otros".
```{r}
titles_train_countries_wide <- titles_train_trans %>%
  mutate(production_countries = str_replace_all(production_countries,"[^A-Za-z,]","")) %>% 
  separate_rows(production_countries, sep = ',') %>% 
  filter(production_countries != '') %>%
  mutate(production_countries = fct_lump_n(production_countries, 10, other_level = "Otros"))
```

Podemos comprobar de nuevo como queda la distribucion de factores posterior a esta manipulacion.
```{r}
titles_train_countries_wide %>% count(production_countries) %>% 
  ggplot(aes(x = production_countries, y = n)) +
  geom_col()
```

El factor 'Otros' recopila bastantes valores. Puede que mas adelante sea mas conveniente crear una sola columna que sea "US" u "Otros" para condensar mejor la distribucion pero ahora procedemos de esta manera. 

Ahora si podemos replicar el abordaje que seguimos con el genero y convertir cada factor en una columna separada. Lo unico que hay que hacer es eliminar los duplicados porque hay peliculas que titulos repetidos dado que tenian distintos paises asignados pero estos distintos paises se convirtieron en la misma categoria dejando a las filas como repetidas. 
```{r}
titles_train_countries_wide <- titles_train_trans %>% 
  mutate(dummy = 1) %>% 
  na_if("") %>%
  distinct() %>%
  pivot_wider(names_from = production_countries, values_from = dummy) %>% 
  mutate(
    across(any_of(levels(titles_train_trans$production_countries)), ~ replace_na(.x, 0))
    )
```

## a)
```{r}
titles_train %>% 
  mutate(genres = str_replace_all(genres,"[^A-Za-z,]","")) %>% 
  separate_rows(genres, sep = ',') %>% filter(genres != '') %>%
  ggplot(
    aes(x = genres, y = imdb_score)
  ) +
    geom_boxplot()+
  theme(axis.text.x = element_text(angle = 45, hjust=1))
```
## b)

Exploramos el puntaje a lo largo de los aÃ±os
```{r}
titles_train %>% 
  mutate(genres = str_replace_all(genres,"[^A-Za-z,]","")) %>% 
  separate_rows(genres, sep = ',') %>% filter(genres != '', !is.na(imdb_score)) %>%
  ggplot(aes(x= release_year, y=imdb_score)) +
    geom_line() +
    geom_point()
   
```

Ahora lo hacemos en base al genero
```{r}
titles_train %>% 
  mutate(genres = str_replace_all(genres,"[^A-Za-z,]","")) %>% 
  separate_rows(genres, sep = ',') %>% filter(genres != '', !is.na(imdb_score)) %>%
  ggplot(aes(x=release_year, y=imdb_score, color = genres)) +
    geom_line() +
    facet_wrap("genres") +
   theme(axis.text.x = element_text(angle = 45, hjust=1))
   
```

## c)

Para explorar lo pedido, se combinan el dataframe que contiene la informacion de las personas que ocupan rol de director o actor, y el dataframe que contiene la informacion del puntaje imdb, utilizando la columna llave "id". Luego se imprimen los 10 actores o directores que mejores y peores puntajes tienen.
```{r}
# Primero combino credits_train con titles_train utilizando la columna "id"
titulos_creditos_combinados<- inner_join(titles_train, credits_train, by = "id")

# Veo los 10 actores o directores que mejores puntajes tienen
titulos_creditos_combinados %>%
  group_by(titulos_creditos_combinados$person_id) %>%
  summarise(mean = mean(imdb_score)) %>%
  top_n(10)

# Veo los 10 actores o directores que peores puntajes tienen
titulos_creditos_combinados %>%
  group_by(titulos_creditos_combinados$person_id) %>%
  summarise(mean = mean(imdb_score)) %>%
  top_n(-10)

```

## d)

Se tomara la columna imdb_votes como una medida de popularidad, suponiendo que la cantidad de votos estaria asociado con la cantidad de personas que ven un film determinado.
Pareceria ser que la cantidad de votos y el puntaje esta asociado de manera postiva.
```{r}
titles_train %>%
  ggplot(aes(imdb_votes, imdb_score)) +
    geom_point()

# ahora me fijo en los que tienen menos de 250000 votos
titles_train %>%
  ggplot(aes(imdb_votes, imdb_score)) +
    geom_point() +
    xlim(0,250000)
```

## e)

```{r}
library(tidytext)
```

Primero armo un nuevo dataframe con las palabras tokenizadas de los titulos de las peliculas.

```{r}
data("stop_words")

token_titles <- titles_train %>%
  #Convierto los titulos de las peliculas en string porque esta como factor
  mutate(title = as.character(title)) %>%
  #Saco unicamente las columnas que me interesan que son el id, el titulo y el puntaje.
  select(id, title, imdb_score) %>%
  #Tokenizo la columna del titulo
  unnest_tokens(palabras, title) %>% 
  #Agrupo por id
  group_by(id) %>%
  #Calculo la posicion de cada palabra en el titulo aprovechando que agrupe por id
  mutate(word_number = row_number()) %>%
  #Elimino las stopwords
  filter(!palabras %in% stop_words$word) %>%
  ungroup()
```

Calculo ahora la mediana de puntaje para cada palabra y me quedo con aquellas palabras que aparezcan mas de una determinada cantidad de veces. Para definir esto ultimo primero miramos un histograma en escala logaritmica del eje y para ver mejor el patron.

```{r}
token_titles %>% count(palabras) %>% 
  ggplot(aes(x = n)) + 
  geom_histogram() +
  scale_y_log10()
```

Vamos a suponer que una palabra tuvo que haber aparecido por lo menos 15 veces para ser contabilizada con lo cual filtramos las palabras con menos de 15 apariciones. Luego de lo cual podemos filtrar los titulos que no tienen puntaje de imdb, agrupamos por palabra y calculamos la mediana para graficar.

```{r}
mediana_titles <- token_titles %>%
  filter(
    palabras %in% (token_titles %>% count(palabras) %>% filter(n >= 15) %>% pull(palabras))
  ) %>%
  filter(!is.na(imdb_score)) %>%
  group_by(palabras) %>%
  summarise(mediana = median(imdb_score))

mediana_titles %>%
  ggplot(aes(x = reorder(palabras, -mediana), y = mediana)) +
  geom_segment(aes(x = reorder(palabras, -mediana), xend = reorder(palabras, -mediana), y = 5, yend = mediana)) +
  geom_point() +
  ylab('Median score') + xlab('Words') +
  coord_flip()
```
Quedaron algunas stopwords de otros idiomas como el espaÃ±ol que no fueron captadas por el dataframe de stopwords que utilizamos. Para eliminarlas habria que utilizar alguna referencia de stopwords con mayor representacion multilinguistica. 

# 2

Agarro el df que tenia los paises en una coluna, y agrupo todos los que son menores de 5 en la categoria "otros"
```{r}
titles_train_trans_OtrosPaises <- titles_train_trans %>%
  mutate(production_countries = str_replace_all(production_countries,"[^A-Za-z,]","")) %>% 
  separate_rows(production_countries, sep = ',') %>% 
  filter(production_countries != '',!is.na(imdb_score)) %>%
  mutate(production_countries = fct_lump_min(production_countries, 5, other_level = "Otros"))
```

## a)

Corro un modelo lineal para predecir el puntaje de imdb con production_countries. El modelo es de efectos fijos.
```{r}
m_EfectosFijos <- lm(imdb_score ~ production_countries, data = titles_train_trans_OtrosPaises)

summary(m_EfectosFijos)
```

## b)

Corro un modelo lineal multiple mixto para predecir el puntaje de imdb con production_countries. El modelo tiene la intercept como efecto fijo, mas un efecto aleatorio por production_countries.
```{r}
library(lme4)
m_InterceptAleatoria <- lmer(imdb_score ~ (1|production_countries), data = titles_train_trans_OtrosPaises)

summary(m_InterceptAleatoria)
ranef(m_InterceptAleatoria)
```

## c)

Uilizando el script realizado por el profesor en clase, grafico las intercepts fijas y aleatorias 
```{r}
# calculo en numero de casos de production_countries
n_casos_production_countries = titles_train_trans_OtrosPaises %>% 
  group_by(production_countries) %>% 
  summarise(num_cases = n()) %>% 
  pull(num_cases)

# Obtengo intercepts aleatorios con fit_3
lmm_intercepts = ranef(m_InterceptAleatoria)[['production_countries']][,1] +fixef(m_InterceptAleatoria)[['(Intercept)']]

# Obtengo intercepts fijos con fit_1
fixed_intercepts = as.array(m_EfectosFijos$coefficients) 
# le sumo la intercept a cada beta del modelo fijo para que esten mas cercanos a las intercept del modelo mixto y los pueda comparar
fixed_intercepts = c(fixed_intercepts[1],
                     as.array(m_EfectosFijos$coefficients)[2:length(fixed_intercepts)]+fixed_intercepts[1])

# Grafico efectos fijos vs efectos aleatorios, incluyendo el tamano de muestra como size
tibble(lmm = lmm_intercepts, 
       fixed = fixed_intercepts, 
       num_cases = n_casos_production_countries,
       pr_count = sort(unique(titles_train_trans_OtrosPaises$production_countries))) %>%
  mutate(rn = row_number()) %>% 
  pivot_longer(c(fixed, lmm)) %>% 
  ggplot(aes(x = rn, y = value, label= pr_count, color = name)) +
  geom_point(aes(size = num_cases), alpha = 0.5) +
  geom_text(hjust=0, vjust=0) +
  theme_bw()

## En el grafico se puede ver que los paises que tienen una mayor cantidad de casos los afecta menos si se utiliza un modelo de efectos aleatorios o un modelo de efectos fijos. Cuando los paises tienen pocos casos, desde el modelo de efectos aleatorios, se acercan mas hacia la media, en comparacion con lo que hace con esos mismos paises el modelo de efectos fijos. 
```

# 3

## a)

Agregamos al modelo del item 2b (el de la intercept aleatoria por paises) el predictor release_year, y luego decidimos si valio la pena utilizando anova 
```{r}
# corro el modelo
m2_InterceptAleatoria_release_year <- lmer(imdb_score ~ release_year + (1|production_countries), data = titles_train_trans_OtrosPaises)

# veo los resultados
summary(m2_InterceptAleatoria_release_year)
ranef(m2_InterceptAleatoria_release_year)

# decido si vale la pena sumar al modelo la variable release_year usando anova
anova(m_InterceptAleatoria,
      m2_InterceptAleatoria_release_year)

# basado en el resultado del anova, pareceria que si valdria la pena agregar release_year al modelo del item 2b
```

## b)

Separo en datos de entrenamiento y de testeo y comparo m_InterceptAleatoria y m2_InterceptAleatoria_release_year y selecciono el que tenga un menor error cuadratico medio en los datos del testeo.
```{r}
# divido en datos de entrenamiento y de testeo
entrenamiento <- titles_train_trans_OtrosPaises %>%
  slice_sample(prop = 0.8)

testeo <- titles_train_trans_OtrosPaises %>%
  slice(-pull(entrenamiento,X))

# entreno los modelos en la data de entrenamiento

m_InterceptAleatoria_entrenamiento <- lmer(imdb_score ~ (1|production_countries), data = entrenamiento)

m2_InterceptAleatoria_release_year_entrenamiento <- lmer(imdb_score ~ release_year + (1|production_countries), data = entrenamiento)

# predigo usando la data de testeo con el primer modelo
predicciones_m <- predict(m_InterceptAleatoria_entrenamiento, testeo)

# predigo usando la data de testeo con el segundo modelo
predicciones_m2 <- predict(m2_InterceptAleatoria_release_year_entrenamiento, testeo)

# creo una funcion que calcule el error cuadratico medio
error_cuadratico_medio <- function(y_predic, y){
  error <- mean((y - y_predic)**2)
  return(error)
}

error_cuadratico_medio_m <- error_cuadratico_medio(predicciones_m, testeo$imdb_score)
error_cuadratico_medio_m2 <- error_cuadratico_medio(predicciones_m2, testeo$imdb_score)
```

## c) Mientras que el anova muestra una significancia estadistica al agregar el predictor release_year con respecto al modelo que no tiene este predictor, el error cuadratico medio al comparar ambos predictores no pareciera ser abismal. El anova mide como impacta el hecho de agregar un predictor (release_year) en los residuales. En este caso, impacto de manera significativa. Sin embargo, el error cuadratico medio, que evalua que tan bien predice el modelo, pareciera no variar en gran medida al agregar el predictor "release_year". El error cuadratico medio es una metrica predictiva. Ademas el anova supone una cierta distrubicion, con ciertos grados de libertad, es decir, es una metrica parametrica. A diferencia del error cuadratico medio, que es no parametrico.

-----

En el punto 4 fijar un parametro de penalizacion
